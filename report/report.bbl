\begin{thebibliography}{}

\bibitem[Denil et~al., 2013]{pred}
Denil, M., Shakibi, B., Dinh, L., Ranzato, M.~A., and de~Freitas, N. (2013).
\newblock {Predicting Parameters in Deep Learning}.
\newblock In Burges, C. J.~C., Bottou, L., Welling, M., Ghahramani, Z., and
  Weinberger, K.~Q., editors, {\em Advances in Neural Information Processing
  Systems 26}, pages 2148--2156. Curran Associates, Inc.

\bibitem[Finn et~al., 2017]{maml}
Finn, C., Abbeel, P., and Levine, S. (2017).
\newblock {Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks}.
\newblock {\em CoRR}, abs/1703.03400.

\bibitem[Gildenblat, 2017]{jacobgilblog}
Gildenblat, J. (2017).
\newblock {Pruning Deep Neural Networks to Make Them Fast and Small}.

\bibitem[Gordon et~al., 2018]{morphnet}
Gordon, A., Eban, E., Nachum, O., Chen, B., Wu, H., Yang, T.-J., and Choi, E.
  (2018).
\newblock {MorphNet: Fast \& Simple Resource-Constrained Structure Learning of
  Deep Networks}.

\bibitem[Han et~al., 2015]{NIPS_learning_weights_pruning}
Han, S., Pool, J., Tran, J., and Dally, W.~J. (2015).
\newblock {Learning Both Weights and Connections for Efficient Neural
  Networks}.
\newblock In {\em {Proceedings of the 28th International Conference on Neural
  Information Processing Systems - Volume 1}}, {NIPS'15}, pages 1135--1143,
  Cambridge, MA, USA. MIT Press.

\bibitem[{Hassibi} et~al., 1993]{OBS}
{Hassibi}, B., {Stork}, D.~G., and {Wolff}, G.~J. (1993).
\newblock {Optimal Brain Surgeon and General Network Pruning}.
\newblock In {\em IEEE International Conference on Neural Networks}, pages
  293--299 vol.1.

\bibitem[LeCun et~al., 1990]{OBD}
LeCun, Y., Denker, J.~S., and Solla, S.~A. (1990).
\newblock {Advances in Neural Information Processing Systems 2}.
\newblock chapter Optimal Brain Damage, pages 598--605. Morgan Kaufmann
  Publishers Inc., San Francisco, CA, USA.

\bibitem[Liu et~al., 2019]{prune_for_architecture}
Liu, Z., Sun, M., Zhou, T., Huang, G., and Darrell, T. (2019).
\newblock {Rethinking the Value of Network Pruning}.
\newblock In {\em International Conference on Learning Representations}.

\bibitem[Louizos et~al., 2018]{L0norm}
Louizos, C., Welling, M., and Kingma, D.~P. (2018).
\newblock {Learning Sparse Neural Networks through L0 Regularization}.
\newblock In {\em International Conference on Learning Representations}.

\bibitem[Molchanov et~al., 2017]{prune_transfer_learning}
Molchanov, P., Tyree, S., Karras, T., Aila, T., and Kautz, J. (2017).
\newblock {Pruning Convolutional Neural Networks for Resource Efficient
  Inference}.
\newblock {\em CoRR}, abs/1611.06440.

\bibitem[Nichol et~al., 2018]{reptile}
Nichol, A., Achain, J., and Schulman, J. (2018).
\newblock {On First-Order Meta-Learning Algorithms}.
\newblock {\em CoRR}, abs/1803.02999.

\end{thebibliography}
