{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pruning_units.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "_5AJjslGcFHi",
        "b031iPnkif-H",
        "Sg4OKhtHjCrj"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "g0u7P1-w6lxN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Load Data"
      ]
    },
    {
      "metadata": {
        "id": "yqrwA42L7mgF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torch.nn as nn\n",
        "import torch.nn.parallel\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data\n",
        "import torchvision as tv\n",
        "import torchvision.models as models\n",
        "from PIL import Image\n",
        "import glob\n",
        "import os\n",
        "import time\n",
        "from torch.optim import lr_scheduler\n",
        "import copy\n",
        "\n",
        "\n",
        "class DatasetManager:\n",
        "    \n",
        "    def __init__(self, dataset = 'cifar10', percent_data = 10.0, percent_val = 20.0, data_path = './data'):\n",
        "        \n",
        "        # 'dataset' can be 'hymenoptera', 'cifar10', or 'cifar100'.\n",
        "        # 'percent_data' is the percentage of the full training set to be used.\n",
        "        # 'percent_val' is the percentage of the *loaded* training set to be used as validation data.\n",
        "        \n",
        "        self.dataset = dataset\n",
        "        self.data_path = data_path\n",
        "        self.percent_data = percent_data\n",
        "        self.percent_val = percent_val\n",
        "        \n",
        "        if self.dataset == 'hymenoptera':\n",
        "\n",
        "            self.transform = tv.transforms.Compose([\n",
        "                tv.transforms.RandomResizedCrop(224),\n",
        "                tv.transforms.RandomHorizontalFlip(),\n",
        "                tv.transforms.ToTensor(),\n",
        "                tv.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "            \n",
        "        elif self.dataset == 'cifar10' or self.dataset == 'cifar100':\n",
        "\n",
        "            self.transform = tv.transforms.Compose([\n",
        "                tv.transforms.RandomResizedCrop(224),\n",
        "                tv.transforms.RandomHorizontalFlip(),\n",
        "                tv.transforms.ToTensor(),\n",
        "                tv.transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))])\n",
        "        \n",
        "        return\n",
        "    \n",
        "    \n",
        "    def ImportDataset(self, batch_size=5):\n",
        "        \n",
        "        self.batch_size = batch_size\n",
        "        \n",
        "        if self.dataset == 'hymenoptera':\n",
        "        \n",
        "            self.trainset = tv.datasets.ImageFolder(root=self.data_path,\n",
        "                             transform=self.transform)\n",
        "        \n",
        "        # todo\n",
        "        \n",
        "        elif self.dataset == 'cifar10':\n",
        "\n",
        "            self.trainset = tv.datasets.CIFAR10(root=self.data_path, train=True,\n",
        "                                        download=True, transform=self.transform)\n",
        "\n",
        "            self.testset = tv.datasets.CIFAR10(root=self.data_path, train=False,\n",
        "                                       download=True, transform=self.transform)\n",
        "        \n",
        "        elif self.dataset == 'cifar100':\n",
        "\n",
        "            self.trainset = tv.datasets.CIFAR100(root=self.data_path, train=True,\n",
        "                                        download=True, transform=self.transform)\n",
        "\n",
        "            self.testset = tv.datasets.CIFAR100(root=self.data_path, train=False,\n",
        "                                       download=True, transform=self.transform)\n",
        "             \n",
        "        self.SplitData();\n",
        "        self.GenerateLoaders();\n",
        "                \n",
        "        return\n",
        "    \n",
        "    \n",
        "    def SplitData(self):\n",
        "        \n",
        "        len_full = self.trainset.__len__()\n",
        "        len_train = int(np.round(len_full*self.percent_data/100.0))\n",
        "        \n",
        "        _, self.trainset = torch.utils.data.random_split(self.trainset, (len_full-len_train, len_train))\n",
        "        \n",
        "        len_val = int(np.round(len_train*self.percent_val/100.0))\n",
        "        len_train = len_train - len_val\n",
        "        \n",
        "        self.valset, self.trainset = torch.utils.data.random_split(self.trainset, (len_val, len_train))\n",
        "         \n",
        "        len_full_test = self.testset.__len__()\n",
        "        len_test = int(np.round(len_full_test*self.percent_data/100.0))\n",
        "        \n",
        "        _, self.testset = torch.utils.data.random_split(self.testset, (len_full_test-len_test, len_test))\n",
        "\n",
        "        print('\\nFull training set size: {}'.format(len_full))\n",
        "        print('Full test set size: {}'.format(len_full_test))\n",
        "        print('\\nActive training set size: {}'.format(len_train))\n",
        "        print('Active validation set size: {}'.format(len_val))\n",
        "        print('Active test set size: {}'.format(len_test))\n",
        "        \n",
        "        return\n",
        "    \n",
        "    \n",
        "    def GenerateLoaders(self):\n",
        "        \n",
        "        self.train_loader = torch.utils.data.DataLoader(self.trainset, batch_size=self.batch_size,\n",
        "                                          shuffle=True, num_workers=0)\n",
        "        self.val_loader = torch.utils.data.DataLoader(self.valset, batch_size=self.batch_size,\n",
        "                                          shuffle=True, num_workers=0)\n",
        "        self.test_loader = torch.utils.data.DataLoader(self.testset, batch_size=self.batch_size,\n",
        "                                          shuffle=True, num_workers=0)          \n",
        "            \n",
        "        return\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fHyU0vpTK2-_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "21c2aedd-ff3c-430a-e0ae-075debf104ca"
      },
      "cell_type": "code",
      "source": [
        "# Import data\n",
        "\n",
        "dat = DatasetManager('cifar10', 10.0, 20.0)\n",
        "dat.ImportDataset(5)\n",
        "\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "\n",
            "Full training set size: 50000\n",
            "Full test set size: 10000\n",
            "\n",
            "Active training set size: 4000\n",
            "Active validation set size: 1000\n",
            "Active test set size: 1000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "SLDvMNwVEPgV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Pruning Functions"
      ]
    },
    {
      "metadata": {
        "id": "Ye1vK3FmREgq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Class that contains various settings pertaining to how filters are pruned\n",
        "class UnitPruningSettings:\n",
        "    \n",
        "    def __init__(self, idx_layer, idx_filter, N_prune = 1, p = 2):\n",
        "        \n",
        "        self.N_prune = N_prune # Number of filters allowed to be pruned in one pass\n",
        "        self.idx_filter = idx_filter # Indices of the N_prune filters\n",
        "        self.idx_layer = idx_layer # Current layer under consideration\n",
        "        self.p = p # p-norm to use when computing which filters to remove\n",
        "        \n",
        "        return\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HnBts6uMEU9t",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# These functions were adapted from https://github.com/jacobgil/pytorch-pruning/blob/master/prune.py\n",
        "\n",
        "def replace_layers(model, i, idx, layers):\n",
        "\tif i in idx:\n",
        "\t\treturn layers[idx.index(i)]\n",
        "\treturn model[i]\n",
        "\n",
        "# Function to prune a given convolution layer in the model provided.\n",
        "# Input \"idx_layers\" is the global index of the convolution layer to be pruned.\n",
        "# Input \"prune_settings\" is a data structure containing information on how pruning is performed.\n",
        "def PruneConvLayers(model, prune_settings):\n",
        "    \n",
        "    # Strategy: in order to prune a particular layer, the output of the previous layer \n",
        "    # and the inputs to the next layer must also be altered accordingly.\n",
        "\t\n",
        "    # Extract pruning settings for convenience\n",
        "    # Note that \"N_prune\" *consecutive* filters will get pruned\n",
        "#     N_prune = prune_settings.N_prune\n",
        "    N_prune = 1\n",
        "    idx_filter = prune_settings.idx_filter\n",
        "    idx_layer = prune_settings.idx_layer\n",
        "    \n",
        "    # Extract the layer of the model currently being pruned\n",
        "    _, conv = list(model.features._modules.items())[idx_layer]\n",
        "#     _, conv = model.features._modules.items()(idx_layer)\n",
        "    \n",
        "    # To keep track of the succeeding convolution layer\n",
        "    next_conv = None\n",
        "    offset = 1\n",
        "    \n",
        "    # Figure out how many layers after this one are NOT conv layers, in order to skip pruning them\n",
        "    while idx_layer + offset < len(model.features._modules.items()):\n",
        "        \n",
        "        res =  list(model.features._modules.items())[idx_layer + offset]\n",
        "        if isinstance(res[1], torch.nn.modules.conv.Conv2d):\n",
        "            next_name, next_conv = res\n",
        "            break\n",
        "        offset = offset + 1\n",
        "    \n",
        "    # Create a new, replacement conv layer to remove a given number of filters.\n",
        "    # The rest of its settings should remain the same as the original conv layer.\n",
        "    new_conv = torch.nn.Conv2d(in_channels = conv.in_channels,\n",
        "                               out_channels = conv.out_channels - N_prune,\n",
        "\t\t\t                   kernel_size = conv.kernel_size,\n",
        "                               stride = conv.stride,\n",
        "                               padding = conv.padding,\n",
        "                               dilation = conv.dilation,\n",
        "                               groups = conv.groups,\n",
        "                               bias = True)\n",
        "    \n",
        "    new_conv.bias = conv.bias\n",
        "    \n",
        "    # Copy over the weights to the new conv layer, except the ones corresponding to the filter to be removed\n",
        "    old_weights = conv.weight.data.cpu().numpy()\n",
        "    new_weights = new_conv.weight.data.cpu().numpy()\n",
        "\n",
        "    # This copies the set of filters up to and excluding the filters to be removed\n",
        "    print(idx_filter)\n",
        "    print(conv.weight.data.size())\n",
        "    new_weights[: idx_filter, :, :, :] = old_weights[: idx_filter, :, :, :]\n",
        "\n",
        "    # This copies the filters after and excluding the filters to be removed\n",
        "    new_weights[idx_filter :, :, :, :] = old_weights[idx_filter + N_prune :, :, :, :]\n",
        "\n",
        "    # Update weight data of the new conv layer\n",
        "    new_conv.weight.data = torch.from_numpy(new_weights).cuda()\n",
        "#     new_conv.weight.data = torch.from_numpy(new_weights)\n",
        "\n",
        "    # Now do the same thing for biases\n",
        "    old_biases = conv.bias.data.cpu().numpy()\n",
        "\n",
        "    new_biases = np.zeros(shape = (old_biases.shape[0] - N_prune), dtype = np.float32)\n",
        "    new_biases[:idx_filter] = old_biases[:idx_filter]\n",
        "    new_biases[idx_filter :] = old_biases[idx_filter + N_prune :]\n",
        "    new_conv.bias.data = torch.from_numpy(new_biases).cuda()\n",
        "#     new_conv.bias.data = torch.from_numpy(new_biases)\n",
        "    \n",
        "    # If there is a succeeding conv layer, adjust its input units and weights accordingly\n",
        "    if next_conv != None:\n",
        "        \n",
        "        next_new_conv = torch.nn.Conv2d(in_channels = next_conv.in_channels - N_prune,\n",
        "                                        out_channels =  next_conv.out_channels,\n",
        "                                        kernel_size = next_conv.kernel_size,\n",
        "                                        stride = next_conv.stride,\n",
        "                                        padding = next_conv.padding,\n",
        "                                        dilation = next_conv.dilation,\n",
        "                                        groups = next_conv.groups,\n",
        "                                        bias = True)\n",
        "        \n",
        "        next_new_conv.bias = next_conv.bias\n",
        "\n",
        "        old_weights = next_conv.weight.data.cpu().numpy()\n",
        "        new_weights = next_new_conv.weight.data.cpu().numpy()\n",
        "\n",
        "        new_weights[:, : idx_filter, :, :] = old_weights[:, : idx_filter, :, :]\n",
        "        new_weights[:, idx_filter : , :, :] = old_weights[:, idx_filter + N_prune :, :, :]\n",
        "        next_new_conv.weight.data = torch.from_numpy(new_weights).cuda()\n",
        "#         next_new_conv.weight.data = torch.from_numpy(new_weights)\n",
        "\n",
        "        next_new_conv.bias.data = next_conv.bias.data\n",
        "\n",
        "        # Update the actual model by replacing the existing filters with the new ones\n",
        "        features = torch.nn.Sequential(\n",
        "                *(replace_layers(model.features, i, [idx_layer, idx_layer + offset], \\\n",
        "                    [new_conv, next_new_conv]) for i, _ in enumerate(model.features)))\n",
        "        del model.features\n",
        "        del conv\n",
        "\n",
        "        model.features = features\n",
        "    \n",
        "    else:\n",
        "\n",
        "        # This is the last conv layer. This affects the first linear layer of the classifier.\n",
        "        model.features = torch.nn.Sequential(\n",
        "                *(replace_layers(model.features, i, [idx_layer], \\\n",
        "                    [new_conv]) for i, _ in enumerate(model.features)))\n",
        "        idx_layer = 0\n",
        "        old_linear_layer = None\n",
        "\n",
        "        for _, module in model.classifier._modules.items():\n",
        "            if isinstance(module, torch.nn.Linear):\n",
        "                old_linear_layer = module\n",
        "                break\n",
        "            idx_layer = idx_layer + 1\n",
        "\n",
        "        if old_linear_layer == None:\n",
        "            raise BaseException(\"No linear layer found in classifier.\")\n",
        "        params_per_input_channel = old_linear_layer.in_features / conv.out_channels\n",
        "\n",
        "        new_linear_layer = \\\n",
        "            torch.nn.Linear(int(old_linear_layer.in_features - params_per_input_channel), \n",
        "                old_linear_layer.out_features)\n",
        "\n",
        "        old_weights = old_linear_layer.weight.data.cpu().numpy()\n",
        "        new_weights = new_linear_layer.weight.data.cpu().numpy()\t \t\n",
        "\n",
        "        new_weights[:, : int(idx_filter * params_per_input_channel)] = \\\n",
        "            old_weights[:, : int(idx_filter * params_per_input_channel)]\n",
        "        new_weights[:, int(idx_filter * params_per_input_channel) :] = \\\n",
        "            old_weights[:, int((idx_filter + N_prune) * params_per_input_channel) :]\n",
        "\n",
        "        new_linear_layer.bias.data = old_linear_layer.bias.data\n",
        "\n",
        "        new_linear_layer.weight.data = torch.from_numpy(new_weights).cuda()\n",
        "#         new_linear_layer.weight.data = torch.from_numpy(new_weights)\n",
        "\n",
        "        classifier = torch.nn.Sequential(\n",
        "            *(replace_layers(model.classifier, i, [idx_layer], \\\n",
        "                [new_linear_layer]) for i, _ in enumerate(model.classifier)))\n",
        "\n",
        "        del model.classifier\n",
        "        del next_conv\n",
        "        del conv\n",
        "        model.classifier = classifier\n",
        "        \n",
        "    return model\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MnKIkiz8QZXZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "2e8ade44-bc65-43c2-e980-0ccf1e3a587c"
      },
      "cell_type": "code",
      "source": [
        "# Test pruning\n",
        "\n",
        "model = models.vgg16(pretrained=True)\n",
        "model.train()\n",
        "\n",
        "# Pruning setup\n",
        "prune_settings = UnitPruningSettings(28, 10, 1)\n",
        "\n",
        "t0 = time.time()\n",
        "model = PruneConvLayers(model, prune_settings)\n",
        "print (\"Pruning took {} s\".format(time.time() - t0))\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10\n",
            "torch.Size([512, 512, 3, 3])\n",
            "Pruning took 5.5924272537231445 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Yn_VPoXdbmPg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Training Function"
      ]
    },
    {
      "metadata": {
        "id": "kvekshfziL_n",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train_model(model, dat, criterion, optimizer, scheduler, num_epochs=25):\n",
        "    \n",
        "    since = time.time()\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch+1, num_epochs))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'val']:\n",
        "            \n",
        "            if phase == 'train':\n",
        "                scheduler.step()\n",
        "                dataloader = dat.train_loader\n",
        "                dataset_size = dat.trainset.__len__()\n",
        "                \n",
        "                model.train()  # Set model to training mode\n",
        "                \n",
        "            else:\n",
        "                \n",
        "                model.eval()   # Set model to evaluate mode\n",
        "                dataloader = dat.val_loader\n",
        "                dataset_size = dat.valset.__len__()\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # Iterate over data.\n",
        "            for inputs, labels in dataloader:\n",
        "                \n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            epoch_loss = running_loss / dataset_size\n",
        "            epoch_acc = running_corrects.double() / dataset_size\n",
        "\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
        "                phase, epoch_loss, epoch_acc))\n",
        "\n",
        "            # deep copy the model\n",
        "            if phase == 'val' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
        "        time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best val Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    \n",
        "    return model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9vpIOd-wiTYf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Baseline Model Setup"
      ]
    },
    {
      "metadata": {
        "id": "6w6D3bRfbrvQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = models.vgg16(pretrained=False)\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Observe that all parameters are being optimized\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# Decay LR by a factor of 0.1 every 7 epochs\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_5AJjslGcFHi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Train Baseline Model"
      ]
    },
    {
      "metadata": {
        "id": "9s7W8AMicIlK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2366
        },
        "outputId": "feca6251-b9e2-40a9-b54a-b829ec404e40"
      },
      "cell_type": "code",
      "source": [
        "# Import data\n",
        "dat = DatasetManager('cifar10', 1.0, 20.0)\n",
        "dat.ImportDataset(5)\n",
        "\n",
        "model.train()\n",
        "\n",
        "model = train_model(model, dat, criterion, optimizer, exp_lr_scheduler, num_epochs=25)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "\n",
            "Full training set size: 50000\n",
            "Full test set size: 10000\n",
            "\n",
            "Active training set size: 400\n",
            "Active validation set size: 100\n",
            "Active test set size: 100\n",
            "Epoch 0/24\n",
            "----------\n",
            "train Loss: 4.3286 Acc: 0.0850\n",
            "val Loss: 2.7769 Acc: 0.1000\n",
            "\n",
            "Epoch 1/24\n",
            "----------\n",
            "train Loss: 2.6722 Acc: 0.0975\n",
            "val Loss: 2.7078 Acc: 0.1500\n",
            "\n",
            "Epoch 2/24\n",
            "----------\n",
            "train Loss: 2.5664 Acc: 0.1025\n",
            "val Loss: 2.6823 Acc: 0.0800\n",
            "\n",
            "Epoch 3/24\n",
            "----------\n",
            "train Loss: 2.5396 Acc: 0.1150\n",
            "val Loss: 2.4599 Acc: 0.0900\n",
            "\n",
            "Epoch 4/24\n",
            "----------\n",
            "train Loss: 2.3716 Acc: 0.1400\n",
            "val Loss: 2.6080 Acc: 0.1300\n",
            "\n",
            "Epoch 5/24\n",
            "----------\n",
            "train Loss: 2.3871 Acc: 0.1775\n",
            "val Loss: 2.3081 Acc: 0.1300\n",
            "\n",
            "Epoch 6/24\n",
            "----------\n",
            "train Loss: 2.2874 Acc: 0.1800\n",
            "val Loss: 2.2540 Acc: 0.1400\n",
            "\n",
            "Epoch 7/24\n",
            "----------\n",
            "train Loss: 2.1119 Acc: 0.2425\n",
            "val Loss: 2.0886 Acc: 0.2000\n",
            "\n",
            "Epoch 8/24\n",
            "----------\n",
            "train Loss: 2.1106 Acc: 0.2125\n",
            "val Loss: 2.1036 Acc: 0.1900\n",
            "\n",
            "Epoch 9/24\n",
            "----------\n",
            "train Loss: 2.0800 Acc: 0.2350\n",
            "val Loss: 2.0900 Acc: 0.2100\n",
            "\n",
            "Epoch 10/24\n",
            "----------\n",
            "train Loss: 2.0629 Acc: 0.2625\n",
            "val Loss: 2.1176 Acc: 0.1500\n",
            "\n",
            "Epoch 11/24\n",
            "----------\n",
            "train Loss: 2.0317 Acc: 0.2225\n",
            "val Loss: 2.1615 Acc: 0.1300\n",
            "\n",
            "Epoch 12/24\n",
            "----------\n",
            "train Loss: 2.0667 Acc: 0.2175\n",
            "val Loss: 2.0595 Acc: 0.2100\n",
            "\n",
            "Epoch 13/24\n",
            "----------\n",
            "train Loss: 2.0705 Acc: 0.2100\n",
            "val Loss: 2.0867 Acc: 0.1800\n",
            "\n",
            "Epoch 14/24\n",
            "----------\n",
            "train Loss: 2.0335 Acc: 0.2475\n",
            "val Loss: 2.0628 Acc: 0.2100\n",
            "\n",
            "Epoch 15/24\n",
            "----------\n",
            "train Loss: 2.0347 Acc: 0.2375\n",
            "val Loss: 2.0819 Acc: 0.1700\n",
            "\n",
            "Epoch 16/24\n",
            "----------\n",
            "train Loss: 2.0334 Acc: 0.2275\n",
            "val Loss: 2.1020 Acc: 0.1800\n",
            "\n",
            "Epoch 17/24\n",
            "----------\n",
            "train Loss: 2.0137 Acc: 0.2475\n",
            "val Loss: 2.0503 Acc: 0.1900\n",
            "\n",
            "Epoch 18/24\n",
            "----------\n",
            "train Loss: 2.0213 Acc: 0.2400\n",
            "val Loss: 2.1022 Acc: 0.1800\n",
            "\n",
            "Epoch 19/24\n",
            "----------\n",
            "train Loss: 2.0346 Acc: 0.2400\n",
            "val Loss: 2.1254 Acc: 0.1500\n",
            "\n",
            "Epoch 20/24\n",
            "----------\n",
            "train Loss: 2.0281 Acc: 0.2375\n",
            "val Loss: 2.1592 Acc: 0.2000\n",
            "\n",
            "Epoch 21/24\n",
            "----------\n",
            "train Loss: 2.0396 Acc: 0.2375\n",
            "val Loss: 2.1035 Acc: 0.1800\n",
            "\n",
            "Epoch 22/24\n",
            "----------\n",
            "train Loss: 2.0304 Acc: 0.2300\n",
            "val Loss: 2.1190 Acc: 0.1900\n",
            "\n",
            "Epoch 23/24\n",
            "----------\n",
            "train Loss: 2.0441 Acc: 0.2325\n",
            "val Loss: 2.0977 Acc: 0.1700\n",
            "\n",
            "Epoch 24/24\n",
            "----------\n",
            "train Loss: 2.0452 Acc: 0.2425\n",
            "val Loss: 2.0960 Acc: 0.1700\n",
            "\n",
            "Training complete in 5m 35s\n",
            "Best val Acc: 0.210000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "b031iPnkif-H",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Pruned Model Setup - Single Filter"
      ]
    },
    {
      "metadata": {
        "id": "IbwrbOviikWF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a55f15d5-2f8f-48fa-c5fc-06e759029776"
      },
      "cell_type": "code",
      "source": [
        "model = models.vgg16(pretrained=True)\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "\n",
        "# Pruning setup\n",
        "prune_settings = UnitPruningSettings(28, 10, 1)\n",
        "\n",
        "t0 = time.time()\n",
        "model = PruneConvLayers(model, prune_settings)\n",
        "print (\"Pruning took {} s\".format(time.time() - t0))\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Observe that all parameters are being optimized\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# Decay LR by a factor of 0.1 every 7 epochs\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Pruning took 1.4709546566009521 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Sg4OKhtHjCrj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Train Pruned Model - Single Filter"
      ]
    },
    {
      "metadata": {
        "id": "AKXgtuR0jJf2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2366
        },
        "outputId": "c10dc6be-5e8a-4268-cbaf-42b02313244b"
      },
      "cell_type": "code",
      "source": [
        "# Import data\n",
        "dat = DatasetManager('cifar10', 1.0, 20.0)\n",
        "dat.ImportDataset(5)\n",
        "\n",
        "model.train()\n",
        "\n",
        "model = train_model(model, dat, criterion, optimizer, exp_lr_scheduler, num_epochs=25)\n"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "\n",
            "Full training set size: 50000\n",
            "Full test set size: 10000\n",
            "\n",
            "Active training set size: 400\n",
            "Active validation set size: 100\n",
            "Active test set size: 100\n",
            "Epoch 0/24\n",
            "----------\n",
            "train Loss: 2.8876 Acc: 0.0875\n",
            "val Loss: 2.3552 Acc: 0.1900\n",
            "\n",
            "Epoch 1/24\n",
            "----------\n",
            "train Loss: 2.4806 Acc: 0.1275\n",
            "val Loss: 2.2240 Acc: 0.1800\n",
            "\n",
            "Epoch 2/24\n",
            "----------\n",
            "train Loss: 2.3176 Acc: 0.1900\n",
            "val Loss: 2.1939 Acc: 0.2000\n",
            "\n",
            "Epoch 3/24\n",
            "----------\n",
            "train Loss: 2.2381 Acc: 0.1875\n",
            "val Loss: 2.1577 Acc: 0.2000\n",
            "\n",
            "Epoch 4/24\n",
            "----------\n",
            "train Loss: 2.1509 Acc: 0.2350\n",
            "val Loss: 2.1055 Acc: 0.1900\n",
            "\n",
            "Epoch 5/24\n",
            "----------\n",
            "train Loss: 2.1236 Acc: 0.2425\n",
            "val Loss: 2.0256 Acc: 0.2600\n",
            "\n",
            "Epoch 6/24\n",
            "----------\n",
            "train Loss: 1.8307 Acc: 0.3250\n",
            "val Loss: 1.8670 Acc: 0.2900\n",
            "\n",
            "Epoch 7/24\n",
            "----------\n",
            "train Loss: 1.7686 Acc: 0.3500\n",
            "val Loss: 1.9131 Acc: 0.3200\n",
            "\n",
            "Epoch 8/24\n",
            "----------\n",
            "train Loss: 1.7535 Acc: 0.3400\n",
            "val Loss: 1.8303 Acc: 0.3400\n",
            "\n",
            "Epoch 9/24\n",
            "----------\n",
            "train Loss: 1.6652 Acc: 0.4000\n",
            "val Loss: 1.8468 Acc: 0.3600\n",
            "\n",
            "Epoch 10/24\n",
            "----------\n",
            "train Loss: 1.6122 Acc: 0.4050\n",
            "val Loss: 1.7168 Acc: 0.4300\n",
            "\n",
            "Epoch 11/24\n",
            "----------\n",
            "train Loss: 1.5730 Acc: 0.4050\n",
            "val Loss: 1.8190 Acc: 0.3100\n",
            "\n",
            "Epoch 12/24\n",
            "----------\n",
            "train Loss: 1.6161 Acc: 0.4000\n",
            "val Loss: 1.7363 Acc: 0.3600\n",
            "\n",
            "Epoch 13/24\n",
            "----------\n",
            "train Loss: 1.4759 Acc: 0.4650\n",
            "val Loss: 1.6957 Acc: 0.4200\n",
            "\n",
            "Epoch 14/24\n",
            "----------\n",
            "train Loss: 1.5155 Acc: 0.4475\n",
            "val Loss: 1.8601 Acc: 0.3300\n",
            "\n",
            "Epoch 15/24\n",
            "----------\n",
            "train Loss: 1.5061 Acc: 0.4800\n",
            "val Loss: 1.8389 Acc: 0.3500\n",
            "\n",
            "Epoch 16/24\n",
            "----------\n",
            "train Loss: 1.5602 Acc: 0.4375\n",
            "val Loss: 1.7337 Acc: 0.3400\n",
            "\n",
            "Epoch 17/24\n",
            "----------\n",
            "train Loss: 1.5198 Acc: 0.4625\n",
            "val Loss: 1.7519 Acc: 0.3600\n",
            "\n",
            "Epoch 18/24\n",
            "----------\n",
            "train Loss: 1.4680 Acc: 0.4800\n",
            "val Loss: 1.7563 Acc: 0.3100\n",
            "\n",
            "Epoch 19/24\n",
            "----------\n",
            "train Loss: 1.4432 Acc: 0.5250\n",
            "val Loss: 1.6784 Acc: 0.4000\n",
            "\n",
            "Epoch 20/24\n",
            "----------\n",
            "train Loss: 1.4341 Acc: 0.4700\n",
            "val Loss: 1.8538 Acc: 0.2700\n",
            "\n",
            "Epoch 21/24\n",
            "----------\n",
            "train Loss: 1.5188 Acc: 0.4375\n",
            "val Loss: 1.8839 Acc: 0.3100\n",
            "\n",
            "Epoch 22/24\n",
            "----------\n",
            "train Loss: 1.4668 Acc: 0.4550\n",
            "val Loss: 1.7525 Acc: 0.3800\n",
            "\n",
            "Epoch 23/24\n",
            "----------\n",
            "train Loss: 1.5095 Acc: 0.4525\n",
            "val Loss: 1.8141 Acc: 0.3200\n",
            "\n",
            "Epoch 24/24\n",
            "----------\n",
            "train Loss: 1.4857 Acc: 0.4775\n",
            "val Loss: 1.7037 Acc: 0.4900\n",
            "\n",
            "Training complete in 14m 40s\n",
            "Best val Acc: 0.490000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "1slyZpAjY0yQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Functions to Compute Filter Metrics"
      ]
    },
    {
      "metadata": {
        "id": "ryg9vNTsY8Oc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "3576c580-710f-4dd4-99a8-61855ad94a12"
      },
      "cell_type": "code",
      "source": [
        "# Function to compute the p-norm of weights in all filters of a given layer.\n",
        "# The list of norms are returned in a list in the same order as that in which filters of that layer are stored.\n",
        "def ComputeConv2DFilterNorms(model, idx_layer, p):\n",
        "    \n",
        "    # Extract the layer of the model currently being considered\n",
        "    _, conv = list(model.features._modules.items())[idx_layer]\n",
        "    \n",
        "    weights = conv.weight.data\n",
        "\n",
        "    # Compute norms of each filter\n",
        "    norms = weights.norm(p, dim=2)\n",
        "    norms = norms.norm(p, dim=2)\n",
        "    norms = norms.norm(p, dim=1)\n",
        "    \n",
        "    return norms\n",
        "\n",
        "# Test\n",
        "norms_1 = ComputeConv2DFilterNorms(model, 0, 1)\n",
        "norms_2 = ComputeConv2DFilterNorms(model, 0, 2)\n",
        "norms_inf = ComputeConv2DFilterNorms(model, 0, float('inf'))\n",
        "\n",
        "print(norms_1.size())\n",
        "# print(norms_1)\n",
        "\n",
        "# Compute values and indices of the k smallest norms\n",
        "k = 2\n",
        "n1_botk, ind_n1_botk = torch.topk(norms_1, k, 0, largest=False, sorted=True, out=None)\n",
        "print(n1_botk)\n",
        "print(len(ind_n1_botk))\n",
        "print(ind_n1_botk)\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([64])\n",
            "tensor([0.8986, 0.9685], device='cuda:0')\n",
            "2\n",
            "tensor([43, 54], device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "RvJela053WOj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Function to iterate through all conv2D layers of the network and determine \n",
        "# filters to be pruned, and then carry out the pruning.\n",
        "def PruneAllConv2DLayers(model, prune_settings):\n",
        "    \n",
        "    # Extract pruning settings for convenience\n",
        "    # Note that \"N_prune\" *consecutive* filters will get pruned\n",
        "    N_prune = prune_settings.N_prune\n",
        "    p = prune_settings.p\n",
        "    \n",
        "    # Find the N_prune filters to remove\n",
        "    ii = 1\n",
        "    while ii < len(model.features._modules.items()):\n",
        "        \n",
        "        res = list(model.features._modules.items())[ii]\n",
        "        \n",
        "        if isinstance(res[1], torch.nn.modules.conv.Conv2d):\n",
        "            \n",
        "            # Compute values and indices of the N_prune smallest norms\n",
        "            norms = ComputeConv2DFilterNorms(model, ii, p)\n",
        "            n_botk, ind_botk = torch.topk(norms, N_prune, 0, largest=False, sorted=True, out=None)\n",
        "            \n",
        "            # Prune filters one at a time (todo: prune all at once)\n",
        "            prune_settings.idx_layer = ii\n",
        "            \n",
        "            jj = 0\n",
        "            while jj < len(ind_botk):\n",
        "                prune_settings.idx_filter = ind_botk[jj]\n",
        "#                 print(\"Pruning filter {} in layer {}\".format(ind_botk[jj], ii))\n",
        "                model = PruneConvLayers(model, prune_settings)\n",
        "                jj = jj + 1\n",
        "                \n",
        "        ii = ii + 1\n",
        "    \n",
        "    return model\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2_QHn-nWjih5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Pruned Model Setup - Several Filters"
      ]
    },
    {
      "metadata": {
        "id": "wLvxYCUmeh3Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1278
        },
        "outputId": "55c045ca-36e7-42dc-e54d-8bf7c4a790b0"
      },
      "cell_type": "code",
      "source": [
        "# Test pruning all layers\n",
        "\n",
        "model = models.vgg16(pretrained=False)\n",
        "model.train()\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Observe that all parameters are being optimized\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# Decay LR by a factor of 0.1 every 7 epochs\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
        "\n",
        "# Pruning setup\n",
        "prune_settings = UnitPruningSettings(28, 10, N_prune = 2, p = 2)\n",
        "\n",
        "t0 = time.time()\n",
        "model = PruneAllConv2DLayers(model, prune_settings)\n",
        "print (\"Pruning took {} s\".format(time.time() - t0))\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Pruning filter 12 in layer 2\n",
            "tensor(12, device='cuda:0')\n",
            "torch.Size([64, 64, 3, 3])\n",
            "Pruning filter 47 in layer 2\n",
            "tensor(47, device='cuda:0')\n",
            "torch.Size([63, 64, 3, 3])\n",
            "Pruning filter 47 in layer 5\n",
            "tensor(47, device='cuda:0')\n",
            "torch.Size([128, 62, 3, 3])\n",
            "Pruning filter 27 in layer 5\n",
            "tensor(27, device='cuda:0')\n",
            "torch.Size([127, 62, 3, 3])\n",
            "Pruning filter 76 in layer 7\n",
            "tensor(76, device='cuda:0')\n",
            "torch.Size([128, 126, 3, 3])\n",
            "Pruning filter 29 in layer 7\n",
            "tensor(29, device='cuda:0')\n",
            "torch.Size([127, 126, 3, 3])\n",
            "Pruning filter 57 in layer 10\n",
            "tensor(57, device='cuda:0')\n",
            "torch.Size([256, 126, 3, 3])\n",
            "Pruning filter 198 in layer 10\n",
            "tensor(198, device='cuda:0')\n",
            "torch.Size([255, 126, 3, 3])\n",
            "Pruning filter 158 in layer 12\n",
            "tensor(158, device='cuda:0')\n",
            "torch.Size([256, 254, 3, 3])\n",
            "Pruning filter 74 in layer 12\n",
            "tensor(74, device='cuda:0')\n",
            "torch.Size([255, 254, 3, 3])\n",
            "Pruning filter 60 in layer 14\n",
            "tensor(60, device='cuda:0')\n",
            "torch.Size([256, 254, 3, 3])\n",
            "Pruning filter 34 in layer 14\n",
            "tensor(34, device='cuda:0')\n",
            "torch.Size([255, 254, 3, 3])\n",
            "Pruning filter 435 in layer 17\n",
            "tensor(435, device='cuda:0')\n",
            "torch.Size([512, 254, 3, 3])\n",
            "Pruning filter 251 in layer 17\n",
            "tensor(251, device='cuda:0')\n",
            "torch.Size([511, 254, 3, 3])\n",
            "Pruning filter 2 in layer 19\n",
            "tensor(2, device='cuda:0')\n",
            "torch.Size([512, 510, 3, 3])\n",
            "Pruning filter 281 in layer 19\n",
            "tensor(281, device='cuda:0')\n",
            "torch.Size([511, 510, 3, 3])\n",
            "Pruning filter 361 in layer 21\n",
            "tensor(361, device='cuda:0')\n",
            "torch.Size([512, 510, 3, 3])\n",
            "Pruning filter 282 in layer 21\n",
            "tensor(282, device='cuda:0')\n",
            "torch.Size([511, 510, 3, 3])\n",
            "Pruning filter 151 in layer 24\n",
            "tensor(151, device='cuda:0')\n",
            "torch.Size([512, 510, 3, 3])\n",
            "Pruning filter 240 in layer 24\n",
            "tensor(240, device='cuda:0')\n",
            "torch.Size([511, 510, 3, 3])\n",
            "Pruning filter 114 in layer 26\n",
            "tensor(114, device='cuda:0')\n",
            "torch.Size([512, 510, 3, 3])\n",
            "Pruning filter 292 in layer 26\n",
            "tensor(292, device='cuda:0')\n",
            "torch.Size([511, 510, 3, 3])\n",
            "Pruning filter 493 in layer 28\n",
            "tensor(493, device='cuda:0')\n",
            "torch.Size([512, 510, 3, 3])\n",
            "Pruning filter 333 in layer 28\n",
            "tensor(333, device='cuda:0')\n",
            "torch.Size([511, 510, 3, 3])\n",
            "Pruning took 2.8578286170959473 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "SHixvYRUjpgl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Train Pruned Model - Several Filters"
      ]
    },
    {
      "metadata": {
        "id": "5c5f6i-1jxFD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2366
        },
        "outputId": "8a59cfd0-aef9-46ee-e3ff-01b42b70a06a"
      },
      "cell_type": "code",
      "source": [
        "# Import data\n",
        "dat = DatasetManager('cifar10', 1.0, 20.0)\n",
        "dat.ImportDataset(5)\n",
        "\n",
        "model.train()\n",
        "\n",
        "model = train_model(model, dat, criterion, optimizer, exp_lr_scheduler, num_epochs=25)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "\n",
            "Full training set size: 50000\n",
            "Full test set size: 10000\n",
            "\n",
            "Active training set size: 400\n",
            "Active validation set size: 100\n",
            "Active test set size: 100\n",
            "Epoch 0/24\n",
            "----------\n",
            "train Loss: 4.6155 Acc: 0.0600\n",
            "val Loss: 2.7741 Acc: 0.1000\n",
            "\n",
            "Epoch 1/24\n",
            "----------\n",
            "train Loss: 2.7269 Acc: 0.0875\n",
            "val Loss: 2.5438 Acc: 0.1100\n",
            "\n",
            "Epoch 2/24\n",
            "----------\n",
            "train Loss: 2.6198 Acc: 0.1100\n",
            "val Loss: 2.5260 Acc: 0.1100\n",
            "\n",
            "Epoch 3/24\n",
            "----------\n",
            "train Loss: 2.5160 Acc: 0.1300\n",
            "val Loss: 2.4461 Acc: 0.0900\n",
            "\n",
            "Epoch 4/24\n",
            "----------\n",
            "train Loss: 2.5586 Acc: 0.0875\n",
            "val Loss: 2.3785 Acc: 0.0900\n",
            "\n",
            "Epoch 5/24\n",
            "----------\n",
            "train Loss: 2.4757 Acc: 0.1300\n",
            "val Loss: 2.4116 Acc: 0.1200\n",
            "\n",
            "Epoch 6/24\n",
            "----------\n",
            "train Loss: 2.4929 Acc: 0.1275\n",
            "val Loss: 2.5098 Acc: 0.0900\n",
            "\n",
            "Epoch 7/24\n",
            "----------\n",
            "train Loss: 2.3697 Acc: 0.1650\n",
            "val Loss: 2.3001 Acc: 0.1800\n",
            "\n",
            "Epoch 8/24\n",
            "----------\n",
            "train Loss: 2.3211 Acc: 0.1425\n",
            "val Loss: 2.2758 Acc: 0.1600\n",
            "\n",
            "Epoch 9/24\n",
            "----------\n",
            "train Loss: 2.3416 Acc: 0.1325\n",
            "val Loss: 2.2373 Acc: 0.2200\n",
            "\n",
            "Epoch 10/24\n",
            "----------\n",
            "train Loss: 2.3030 Acc: 0.1375\n",
            "val Loss: 2.2386 Acc: 0.2100\n",
            "\n",
            "Epoch 11/24\n",
            "----------\n",
            "train Loss: 2.2936 Acc: 0.1550\n",
            "val Loss: 2.2335 Acc: 0.2100\n",
            "\n",
            "Epoch 12/24\n",
            "----------\n",
            "train Loss: 2.2774 Acc: 0.1400\n",
            "val Loss: 2.2214 Acc: 0.2500\n",
            "\n",
            "Epoch 13/24\n",
            "----------\n",
            "train Loss: 2.2951 Acc: 0.1525\n",
            "val Loss: 2.2236 Acc: 0.2200\n",
            "\n",
            "Epoch 14/24\n",
            "----------\n",
            "train Loss: 2.2499 Acc: 0.1775\n",
            "val Loss: 2.2127 Acc: 0.2200\n",
            "\n",
            "Epoch 15/24\n",
            "----------\n",
            "train Loss: 2.2882 Acc: 0.1475\n",
            "val Loss: 2.2111 Acc: 0.2300\n",
            "\n",
            "Epoch 16/24\n",
            "----------\n",
            "train Loss: 2.2825 Acc: 0.1350\n",
            "val Loss: 2.2120 Acc: 0.2000\n",
            "\n",
            "Epoch 17/24\n",
            "----------\n",
            "train Loss: 2.2593 Acc: 0.1450\n",
            "val Loss: 2.1932 Acc: 0.2200\n",
            "\n",
            "Epoch 18/24\n",
            "----------\n",
            "train Loss: 2.2618 Acc: 0.1500\n",
            "val Loss: 2.2045 Acc: 0.2200\n",
            "\n",
            "Epoch 19/24\n",
            "----------\n",
            "train Loss: 2.2628 Acc: 0.1550\n",
            "val Loss: 2.2046 Acc: 0.2400\n",
            "\n",
            "Epoch 20/24\n",
            "----------\n",
            "train Loss: 2.2744 Acc: 0.1625\n",
            "val Loss: 2.2270 Acc: 0.2000\n",
            "\n",
            "Epoch 21/24\n",
            "----------\n",
            "train Loss: 2.2582 Acc: 0.1825\n",
            "val Loss: 2.2250 Acc: 0.2100\n",
            "\n",
            "Epoch 22/24\n",
            "----------\n",
            "train Loss: 2.2689 Acc: 0.1375\n",
            "val Loss: 2.2211 Acc: 0.2100\n",
            "\n",
            "Epoch 23/24\n",
            "----------\n",
            "train Loss: 2.2663 Acc: 0.1850\n",
            "val Loss: 2.2202 Acc: 0.1800\n",
            "\n",
            "Epoch 24/24\n",
            "----------\n",
            "train Loss: 2.2435 Acc: 0.1950\n",
            "val Loss: 2.2201 Acc: 0.2000\n",
            "\n",
            "Training complete in 5m 9s\n",
            "Best val Acc: 0.250000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "eWF7Rkytr0D8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Iterative Pruning"
      ]
    },
    {
      "metadata": {
        "id": "hphM-tuDr8Yj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 8895
        },
        "outputId": "f2837cf6-8eb8-4c37-f1ea-9931cac22978"
      },
      "cell_type": "code",
      "source": [
        "# ====== Model setup ======\n",
        "\n",
        "model = models.vgg16(pretrained=False)\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "\n",
        "\n",
        "# ====== Pruning setup ======\n",
        "\n",
        "N_prune = 2\n",
        "p = 2\n",
        "prune_settings = UnitPruningSettings(0, 0, N_prune, p)\n",
        "\n",
        "\n",
        "# ====== Begin training ======\n",
        "\n",
        "N_iter_outer = 5\n",
        "N_iter_inner = 5\n",
        "\n",
        "# Import data\n",
        "dat = DatasetManager(dataset='cifar10', percent_data=1.0, percent_val=20.0)\n",
        "dat.ImportDataset(batch_size=5)\n",
        "\n",
        "for ii in range(0, N_iter_outer):\n",
        "    \n",
        "    print(\"\\n------ Outer iteration {}/{} ------\".format(ii+1, N_iter_outer))\n",
        "#     t0 = time.time()\n",
        "\n",
        "    # ------ Prune current model ------\n",
        "    \n",
        "    model = PruneAllConv2DLayers(model, prune_settings)\n",
        "    new_model = copy.deepcopy(model)\n",
        "    model = new_model\n",
        "\n",
        "    # ------ Train current model ------\n",
        "    \n",
        "#     # Import data\n",
        "#     dat = DatasetManager(dataset='cifar10', percent_data=1.0, percent_val=20.0)\n",
        "#     dat.ImportDataset(batch_size=5)\n",
        "    \n",
        "    # Update optimizer\n",
        "    optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "    # Decay LR by a factor of 0.1 every 7 epochs\n",
        "    exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    \n",
        "    model = train_model(model, dat, criterion, optimizer, exp_lr_scheduler, num_epochs=N_iter_inner)\n",
        "        \n",
        "#     print (\"Pruning took {} s\".format(time.time() - t0))\n",
        "\n",
        "\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "\n",
            "Full training set size: 50000\n",
            "Full test set size: 10000\n",
            "\n",
            "Active training set size: 400\n",
            "Active validation set size: 100\n",
            "Active test set size: 100\n",
            "\n",
            "------ Outer iteration 1/5 ------\n",
            "Pruning filter 44 in layer 2\n",
            "tensor(44, device='cuda:0')\n",
            "torch.Size([64, 64, 3, 3])\n",
            "Pruning filter 5 in layer 2\n",
            "tensor(5, device='cuda:0')\n",
            "torch.Size([63, 64, 3, 3])\n",
            "Pruning filter 40 in layer 5\n",
            "tensor(40, device='cuda:0')\n",
            "torch.Size([128, 62, 3, 3])\n",
            "Pruning filter 50 in layer 5\n",
            "tensor(50, device='cuda:0')\n",
            "torch.Size([127, 62, 3, 3])\n",
            "Pruning filter 23 in layer 7\n",
            "tensor(23, device='cuda:0')\n",
            "torch.Size([128, 126, 3, 3])\n",
            "Pruning filter 115 in layer 7\n",
            "tensor(115, device='cuda:0')\n",
            "torch.Size([127, 126, 3, 3])\n",
            "Pruning filter 31 in layer 10\n",
            "tensor(31, device='cuda:0')\n",
            "torch.Size([256, 126, 3, 3])\n",
            "Pruning filter 58 in layer 10\n",
            "tensor(58, device='cuda:0')\n",
            "torch.Size([255, 126, 3, 3])\n",
            "Pruning filter 92 in layer 12\n",
            "tensor(92, device='cuda:0')\n",
            "torch.Size([256, 254, 3, 3])\n",
            "Pruning filter 95 in layer 12\n",
            "tensor(95, device='cuda:0')\n",
            "torch.Size([255, 254, 3, 3])\n",
            "Pruning filter 247 in layer 14\n",
            "tensor(247, device='cuda:0')\n",
            "torch.Size([256, 254, 3, 3])\n",
            "Pruning filter 127 in layer 14\n",
            "tensor(127, device='cuda:0')\n",
            "torch.Size([255, 254, 3, 3])\n",
            "Pruning filter 348 in layer 17\n",
            "tensor(348, device='cuda:0')\n",
            "torch.Size([512, 254, 3, 3])\n",
            "Pruning filter 415 in layer 17\n",
            "tensor(415, device='cuda:0')\n",
            "torch.Size([511, 254, 3, 3])\n",
            "Pruning filter 89 in layer 19\n",
            "tensor(89, device='cuda:0')\n",
            "torch.Size([512, 510, 3, 3])\n",
            "Pruning filter 219 in layer 19\n",
            "tensor(219, device='cuda:0')\n",
            "torch.Size([511, 510, 3, 3])\n",
            "Pruning filter 93 in layer 21\n",
            "tensor(93, device='cuda:0')\n",
            "torch.Size([512, 510, 3, 3])\n",
            "Pruning filter 78 in layer 21\n",
            "tensor(78, device='cuda:0')\n",
            "torch.Size([511, 510, 3, 3])\n",
            "Pruning filter 321 in layer 24\n",
            "tensor(321, device='cuda:0')\n",
            "torch.Size([512, 510, 3, 3])\n",
            "Pruning filter 213 in layer 24\n",
            "tensor(213, device='cuda:0')\n",
            "torch.Size([511, 510, 3, 3])\n",
            "Pruning filter 505 in layer 26\n",
            "tensor(505, device='cuda:0')\n",
            "torch.Size([512, 510, 3, 3])\n",
            "Pruning filter 17 in layer 26\n",
            "tensor(17, device='cuda:0')\n",
            "torch.Size([511, 510, 3, 3])\n",
            "Pruning filter 488 in layer 28\n",
            "tensor(488, device='cuda:0')\n",
            "torch.Size([512, 510, 3, 3])\n",
            "Pruning filter 306 in layer 28\n",
            "tensor(306, device='cuda:0')\n",
            "torch.Size([511, 510, 3, 3])\n",
            "Epoch 1/5\n",
            "----------\n",
            "train Loss: 4.7381 Acc: 0.0800\n",
            "val Loss: 2.6073 Acc: 0.1400\n",
            "\n",
            "Epoch 2/5\n",
            "----------\n",
            "train Loss: 2.6351 Acc: 0.0750\n",
            "val Loss: 2.5621 Acc: 0.1300\n",
            "\n",
            "Epoch 3/5\n",
            "----------\n",
            "train Loss: 2.5011 Acc: 0.1100\n",
            "val Loss: 2.5174 Acc: 0.1000\n",
            "\n",
            "Epoch 4/5\n",
            "----------\n",
            "train Loss: 2.5654 Acc: 0.0875\n",
            "val Loss: 2.4500 Acc: 0.1000\n",
            "\n",
            "Epoch 5/5\n",
            "----------\n",
            "train Loss: 2.5317 Acc: 0.0875\n",
            "val Loss: 2.4545 Acc: 0.0800\n",
            "\n",
            "Training complete in 1m 9s\n",
            "Best val Acc: 0.140000\n",
            "\n",
            "------ Outer iteration 2/5 ------\n",
            "Pruning filter 50 in layer 2\n",
            "tensor(50, device='cuda:0')\n",
            "torch.Size([62, 64, 3, 3])\n",
            "Pruning filter 30 in layer 2\n",
            "tensor(30, device='cuda:0')\n",
            "torch.Size([61, 64, 3, 3])\n",
            "Pruning filter 49 in layer 5\n",
            "tensor(49, device='cuda:0')\n",
            "torch.Size([126, 60, 3, 3])\n",
            "Pruning filter 60 in layer 5\n",
            "tensor(60, device='cuda:0')\n",
            "torch.Size([125, 60, 3, 3])\n",
            "Pruning filter 114 in layer 7\n",
            "tensor(114, device='cuda:0')\n",
            "torch.Size([126, 124, 3, 3])\n",
            "Pruning filter 39 in layer 7\n",
            "tensor(39, device='cuda:0')\n",
            "torch.Size([125, 124, 3, 3])\n",
            "Pruning filter 8 in layer 10\n",
            "tensor(8, device='cuda:0')\n",
            "torch.Size([254, 124, 3, 3])\n",
            "Pruning filter 57 in layer 10\n",
            "tensor(57, device='cuda:0')\n",
            "torch.Size([253, 124, 3, 3])\n",
            "Pruning filter 94 in layer 12\n",
            "tensor(94, device='cuda:0')\n",
            "torch.Size([254, 252, 3, 3])\n",
            "Pruning filter 201 in layer 12\n",
            "tensor(201, device='cuda:0')\n",
            "torch.Size([253, 252, 3, 3])\n",
            "Pruning filter 18 in layer 14\n",
            "tensor(18, device='cuda:0')\n",
            "torch.Size([254, 252, 3, 3])\n",
            "Pruning filter 226 in layer 14\n",
            "tensor(226, device='cuda:0')\n",
            "torch.Size([253, 252, 3, 3])\n",
            "Pruning filter 414 in layer 17\n",
            "tensor(414, device='cuda:0')\n",
            "torch.Size([510, 252, 3, 3])\n",
            "Pruning filter 104 in layer 17\n",
            "tensor(104, device='cuda:0')\n",
            "torch.Size([509, 252, 3, 3])\n",
            "Pruning filter 218 in layer 19\n",
            "tensor(218, device='cuda:0')\n",
            "torch.Size([510, 508, 3, 3])\n",
            "Pruning filter 67 in layer 19\n",
            "tensor(67, device='cuda:0')\n",
            "torch.Size([509, 508, 3, 3])\n",
            "Pruning filter 64 in layer 21\n",
            "tensor(64, device='cuda:0')\n",
            "torch.Size([510, 508, 3, 3])\n",
            "Pruning filter 135 in layer 21\n",
            "tensor(135, device='cuda:0')\n",
            "torch.Size([509, 508, 3, 3])\n",
            "Pruning filter 23 in layer 24\n",
            "tensor(23, device='cuda:0')\n",
            "torch.Size([510, 508, 3, 3])\n",
            "Pruning filter 174 in layer 24\n",
            "tensor(174, device='cuda:0')\n",
            "torch.Size([509, 508, 3, 3])\n",
            "Pruning filter 435 in layer 26\n",
            "tensor(435, device='cuda:0')\n",
            "torch.Size([510, 508, 3, 3])\n",
            "Pruning filter 316 in layer 26\n",
            "tensor(316, device='cuda:0')\n",
            "torch.Size([509, 508, 3, 3])\n",
            "Pruning filter 190 in layer 28\n",
            "tensor(190, device='cuda:0')\n",
            "torch.Size([510, 508, 3, 3])\n",
            "Pruning filter 302 in layer 28\n",
            "tensor(302, device='cuda:0')\n",
            "torch.Size([509, 508, 3, 3])\n",
            "Epoch 1/5\n",
            "----------\n",
            "train Loss: 2.5808 Acc: 0.1025\n",
            "val Loss: 2.5359 Acc: 0.1000\n",
            "\n",
            "Epoch 2/5\n",
            "----------\n",
            "train Loss: 2.5550 Acc: 0.0950\n",
            "val Loss: 2.5700 Acc: 0.0800\n",
            "\n",
            "Epoch 3/5\n",
            "----------\n",
            "train Loss: 2.5818 Acc: 0.0875\n",
            "val Loss: 2.3598 Acc: 0.1200\n",
            "\n",
            "Epoch 4/5\n",
            "----------\n",
            "train Loss: 2.4815 Acc: 0.0775\n",
            "val Loss: 2.3397 Acc: 0.1600\n",
            "\n",
            "Epoch 5/5\n",
            "----------\n",
            "train Loss: 2.5241 Acc: 0.1075\n",
            "val Loss: 2.3914 Acc: 0.1600\n",
            "\n",
            "Training complete in 1m 8s\n",
            "Best val Acc: 0.160000\n",
            "\n",
            "------ Outer iteration 3/5 ------\n",
            "Pruning filter 13 in layer 2\n",
            "tensor(13, device='cuda:0')\n",
            "torch.Size([60, 64, 3, 3])\n",
            "Pruning filter 10 in layer 2\n",
            "tensor(10, device='cuda:0')\n",
            "torch.Size([59, 64, 3, 3])\n",
            "Pruning filter 95 in layer 5\n",
            "tensor(95, device='cuda:0')\n",
            "torch.Size([124, 58, 3, 3])\n",
            "Pruning filter 59 in layer 5\n",
            "tensor(59, device='cuda:0')\n",
            "torch.Size([123, 58, 3, 3])\n",
            "Pruning filter 81 in layer 7\n",
            "tensor(81, device='cuda:0')\n",
            "torch.Size([124, 122, 3, 3])\n",
            "Pruning filter 10 in layer 7\n",
            "tensor(10, device='cuda:0')\n",
            "torch.Size([123, 122, 3, 3])\n",
            "Pruning filter 56 in layer 10\n",
            "tensor(56, device='cuda:0')\n",
            "torch.Size([252, 122, 3, 3])\n",
            "Pruning filter 162 in layer 10\n",
            "tensor(162, device='cuda:0')\n",
            "torch.Size([251, 122, 3, 3])\n",
            "Pruning filter 200 in layer 12\n",
            "tensor(200, device='cuda:0')\n",
            "torch.Size([252, 250, 3, 3])\n",
            "Pruning filter 104 in layer 12\n",
            "tensor(104, device='cuda:0')\n",
            "torch.Size([251, 250, 3, 3])\n",
            "Pruning filter 225 in layer 14\n",
            "tensor(225, device='cuda:0')\n",
            "torch.Size([252, 250, 3, 3])\n",
            "Pruning filter 18 in layer 14\n",
            "tensor(18, device='cuda:0')\n",
            "torch.Size([251, 250, 3, 3])\n",
            "Pruning filter 407 in layer 17\n",
            "tensor(407, device='cuda:0')\n",
            "torch.Size([508, 250, 3, 3])\n",
            "Pruning filter 201 in layer 17\n",
            "tensor(201, device='cuda:0')\n",
            "torch.Size([507, 250, 3, 3])\n",
            "Pruning filter 47 in layer 19\n",
            "tensor(47, device='cuda:0')\n",
            "torch.Size([508, 506, 3, 3])\n",
            "Pruning filter 300 in layer 19\n",
            "tensor(300, device='cuda:0')\n",
            "torch.Size([507, 506, 3, 3])\n",
            "Pruning filter 134 in layer 21\n",
            "tensor(134, device='cuda:0')\n",
            "torch.Size([508, 506, 3, 3])\n",
            "Pruning filter 201 in layer 21\n",
            "tensor(201, device='cuda:0')\n",
            "torch.Size([507, 506, 3, 3])\n",
            "Pruning filter 173 in layer 24\n",
            "tensor(173, device='cuda:0')\n",
            "torch.Size([508, 506, 3, 3])\n",
            "Pruning filter 200 in layer 24\n",
            "tensor(200, device='cuda:0')\n",
            "torch.Size([507, 506, 3, 3])\n",
            "Pruning filter 229 in layer 26\n",
            "tensor(229, device='cuda:0')\n",
            "torch.Size([508, 506, 3, 3])\n",
            "Pruning filter 95 in layer 26\n",
            "tensor(95, device='cuda:0')\n",
            "torch.Size([507, 506, 3, 3])\n",
            "Pruning filter 165 in layer 28\n",
            "tensor(165, device='cuda:0')\n",
            "torch.Size([508, 506, 3, 3])\n",
            "Pruning filter 301 in layer 28\n",
            "tensor(301, device='cuda:0')\n",
            "torch.Size([507, 506, 3, 3])\n",
            "Epoch 1/5\n",
            "----------\n",
            "train Loss: 2.4753 Acc: 0.1125\n",
            "val Loss: 2.3128 Acc: 0.1400\n",
            "\n",
            "Epoch 2/5\n",
            "----------\n",
            "train Loss: 2.4621 Acc: 0.0950\n",
            "val Loss: 2.4178 Acc: 0.1100\n",
            "\n",
            "Epoch 3/5\n",
            "----------\n",
            "train Loss: 2.4030 Acc: 0.1350\n",
            "val Loss: 2.2504 Acc: 0.1600\n",
            "\n",
            "Epoch 4/5\n",
            "----------\n",
            "train Loss: 2.3167 Acc: 0.1300\n",
            "val Loss: 2.3560 Acc: 0.1400\n",
            "\n",
            "Epoch 5/5\n",
            "----------\n",
            "train Loss: 2.2737 Acc: 0.1500\n",
            "val Loss: 2.4118 Acc: 0.2400\n",
            "\n",
            "Training complete in 1m 8s\n",
            "Best val Acc: 0.240000\n",
            "\n",
            "------ Outer iteration 4/5 ------\n",
            "Pruning filter 48 in layer 2\n",
            "tensor(48, device='cuda:0')\n",
            "torch.Size([58, 64, 3, 3])\n",
            "Pruning filter 39 in layer 2\n",
            "tensor(39, device='cuda:0')\n",
            "torch.Size([57, 64, 3, 3])\n",
            "Pruning filter 65 in layer 5\n",
            "tensor(65, device='cuda:0')\n",
            "torch.Size([122, 56, 3, 3])\n",
            "Pruning filter 26 in layer 5\n",
            "tensor(26, device='cuda:0')\n",
            "torch.Size([121, 56, 3, 3])\n",
            "Pruning filter 24 in layer 7\n",
            "tensor(24, device='cuda:0')\n",
            "torch.Size([122, 120, 3, 3])\n",
            "Pruning filter 56 in layer 7\n",
            "tensor(56, device='cuda:0')\n",
            "torch.Size([121, 120, 3, 3])\n",
            "Pruning filter 161 in layer 10\n",
            "tensor(161, device='cuda:0')\n",
            "torch.Size([250, 120, 3, 3])\n",
            "Pruning filter 53 in layer 10\n",
            "tensor(53, device='cuda:0')\n",
            "torch.Size([249, 120, 3, 3])\n",
            "Pruning filter 142 in layer 12\n",
            "tensor(142, device='cuda:0')\n",
            "torch.Size([250, 248, 3, 3])\n",
            "Pruning filter 140 in layer 12\n",
            "tensor(140, device='cuda:0')\n",
            "torch.Size([249, 248, 3, 3])\n",
            "Pruning filter 218 in layer 14\n",
            "tensor(218, device='cuda:0')\n",
            "torch.Size([250, 248, 3, 3])\n",
            "Pruning filter 154 in layer 14\n",
            "tensor(154, device='cuda:0')\n",
            "torch.Size([249, 248, 3, 3])\n",
            "Pruning filter 1 in layer 17\n",
            "tensor(1, device='cuda:0')\n",
            "torch.Size([506, 248, 3, 3])\n",
            "Pruning filter 398 in layer 17\n",
            "tensor(398, device='cuda:0')\n",
            "torch.Size([505, 248, 3, 3])\n",
            "Pruning filter 299 in layer 19\n",
            "tensor(299, device='cuda:0')\n",
            "torch.Size([506, 504, 3, 3])\n",
            "Pruning filter 460 in layer 19\n",
            "tensor(460, device='cuda:0')\n",
            "torch.Size([505, 504, 3, 3])\n",
            "Pruning filter 200 in layer 21\n",
            "tensor(200, device='cuda:0')\n",
            "torch.Size([506, 504, 3, 3])\n",
            "Pruning filter 454 in layer 21\n",
            "tensor(454, device='cuda:0')\n",
            "torch.Size([505, 504, 3, 3])\n",
            "Pruning filter 199 in layer 24\n",
            "tensor(199, device='cuda:0')\n",
            "torch.Size([506, 504, 3, 3])\n",
            "Pruning filter 392 in layer 24\n",
            "tensor(392, device='cuda:0')\n",
            "torch.Size([505, 504, 3, 3])\n",
            "Pruning filter 455 in layer 26\n",
            "tensor(455, device='cuda:0')\n",
            "torch.Size([506, 504, 3, 3])\n",
            "Pruning filter 202 in layer 26\n",
            "tensor(202, device='cuda:0')\n",
            "torch.Size([505, 504, 3, 3])\n",
            "Pruning filter 300 in layer 28\n",
            "tensor(300, device='cuda:0')\n",
            "torch.Size([506, 504, 3, 3])\n",
            "Pruning filter 245 in layer 28\n",
            "tensor(245, device='cuda:0')\n",
            "torch.Size([505, 504, 3, 3])\n",
            "Epoch 1/5\n",
            "----------\n",
            "train Loss: 2.2308 Acc: 0.1500\n",
            "val Loss: 2.2140 Acc: 0.1300\n",
            "\n",
            "Epoch 2/5\n",
            "----------\n",
            "train Loss: 2.1979 Acc: 0.1925\n",
            "val Loss: 2.2245 Acc: 0.1500\n",
            "\n",
            "Epoch 3/5\n",
            "----------\n",
            "train Loss: 2.1675 Acc: 0.2175\n",
            "val Loss: 2.2117 Acc: 0.1700\n",
            "\n",
            "Epoch 4/5\n",
            "----------\n",
            "train Loss: 2.2066 Acc: 0.2025\n",
            "val Loss: 2.1297 Acc: 0.2100\n",
            "\n",
            "Epoch 5/5\n",
            "----------\n",
            "train Loss: 2.1636 Acc: 0.1950\n",
            "val Loss: 2.0943 Acc: 0.2300\n",
            "\n",
            "Training complete in 1m 6s\n",
            "Best val Acc: 0.230000\n",
            "\n",
            "------ Outer iteration 5/5 ------\n",
            "Pruning filter 25 in layer 2\n",
            "tensor(25, device='cuda:0')\n",
            "torch.Size([56, 64, 3, 3])\n",
            "Pruning filter 29 in layer 2\n",
            "tensor(29, device='cuda:0')\n",
            "torch.Size([55, 64, 3, 3])\n",
            "Pruning filter 58 in layer 5\n",
            "tensor(58, device='cuda:0')\n",
            "torch.Size([120, 54, 3, 3])\n",
            "Pruning filter 32 in layer 5\n",
            "tensor(32, device='cuda:0')\n",
            "torch.Size([119, 54, 3, 3])\n",
            "Pruning filter 55 in layer 7\n",
            "tensor(55, device='cuda:0')\n",
            "torch.Size([120, 118, 3, 3])\n",
            "Pruning filter 65 in layer 7\n",
            "tensor(65, device='cuda:0')\n",
            "torch.Size([119, 118, 3, 3])\n",
            "Pruning filter 126 in layer 10\n",
            "tensor(126, device='cuda:0')\n",
            "torch.Size([248, 118, 3, 3])\n",
            "Pruning filter 142 in layer 10\n",
            "tensor(142, device='cuda:0')\n",
            "torch.Size([247, 118, 3, 3])\n",
            "Pruning filter 19 in layer 12\n",
            "tensor(19, device='cuda:0')\n",
            "torch.Size([248, 246, 3, 3])\n",
            "Pruning filter 200 in layer 12\n",
            "tensor(200, device='cuda:0')\n",
            "torch.Size([247, 246, 3, 3])\n",
            "Pruning filter 182 in layer 14\n",
            "tensor(182, device='cuda:0')\n",
            "torch.Size([248, 246, 3, 3])\n",
            "Pruning filter 184 in layer 14\n",
            "tensor(184, device='cuda:0')\n",
            "torch.Size([247, 246, 3, 3])\n",
            "Pruning filter 130 in layer 17\n",
            "tensor(130, device='cuda:0')\n",
            "torch.Size([504, 246, 3, 3])\n",
            "Pruning filter 397 in layer 17\n",
            "tensor(397, device='cuda:0')\n",
            "torch.Size([503, 246, 3, 3])\n",
            "Pruning filter 459 in layer 19\n",
            "tensor(459, device='cuda:0')\n",
            "torch.Size([504, 502, 3, 3])\n",
            "Pruning filter 492 in layer 19\n",
            "tensor(492, device='cuda:0')\n",
            "torch.Size([503, 502, 3, 3])\n",
            "Pruning filter 453 in layer 21\n",
            "tensor(453, device='cuda:0')\n",
            "torch.Size([504, 502, 3, 3])\n",
            "Pruning filter 268 in layer 21\n",
            "tensor(268, device='cuda:0')\n",
            "torch.Size([503, 502, 3, 3])\n",
            "Pruning filter 391 in layer 24\n",
            "tensor(391, device='cuda:0')\n",
            "torch.Size([504, 502, 3, 3])\n",
            "Pruning filter 345 in layer 24\n",
            "tensor(345, device='cuda:0')\n",
            "torch.Size([503, 502, 3, 3])\n",
            "Pruning filter 461 in layer 26\n",
            "tensor(461, device='cuda:0')\n",
            "torch.Size([504, 502, 3, 3])\n",
            "Pruning filter 170 in layer 26\n",
            "tensor(170, device='cuda:0')\n",
            "torch.Size([503, 502, 3, 3])\n",
            "Pruning filter 291 in layer 28\n",
            "tensor(291, device='cuda:0')\n",
            "torch.Size([504, 502, 3, 3])\n",
            "Pruning filter 418 in layer 28\n",
            "tensor(418, device='cuda:0')\n",
            "torch.Size([503, 502, 3, 3])\n",
            "Epoch 1/5\n",
            "----------\n",
            "train Loss: 2.1286 Acc: 0.2375\n",
            "val Loss: 2.0851 Acc: 0.2300\n",
            "\n",
            "Epoch 2/5\n",
            "----------\n",
            "train Loss: 2.2082 Acc: 0.1800\n",
            "val Loss: 2.1778 Acc: 0.2400\n",
            "\n",
            "Epoch 3/5\n",
            "----------\n",
            "train Loss: 2.1461 Acc: 0.2400\n",
            "val Loss: 2.4534 Acc: 0.1800\n",
            "\n",
            "Epoch 4/5\n",
            "----------\n",
            "train Loss: 2.1366 Acc: 0.2000\n",
            "val Loss: 2.0969 Acc: 0.2000\n",
            "\n",
            "Epoch 5/5\n",
            "----------\n",
            "train Loss: 2.0258 Acc: 0.2325\n",
            "val Loss: 2.1524 Acc: 0.3100\n",
            "\n",
            "Training complete in 1m 7s\n",
            "Best val Acc: 0.310000\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}