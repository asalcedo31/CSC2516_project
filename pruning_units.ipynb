{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pruning_units.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "lc0YTkyADA63"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "tYqrMVdpA1NX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torch.nn as nn\n",
        "import torch.nn.parallel\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data\n",
        "import torchvision as tv\n",
        "import torchvision.models as models\n",
        "from PIL import Image\n",
        "import glob\n",
        "import os\n",
        "import time\n",
        "from torch.optim import lr_scheduler\n",
        "import copy\n",
        "from torch.autograd import Variable\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BhzbK8ntAmnN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Computation Routines"
      ]
    },
    {
      "metadata": {
        "id": "NuhlcxSIA94G",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Load data"
      ]
    },
    {
      "metadata": {
        "id": "YC8SpzkJA8gK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class DatasetManager:\n",
        "    \n",
        "    def __init__(self, dataset = 'cifar10', percent_data = 10.0, percent_val = 20.0, data_path = './data'):\n",
        "        \n",
        "        # 'dataset' can be 'hymenoptera', 'cifar10', or 'cifar100'.\n",
        "        # 'percent_data' is the percentage of the full training set to be used.\n",
        "        # 'percent_val' is the percentage of the *loaded* training set to be used as validation data.\n",
        "        \n",
        "        self.dataset = dataset\n",
        "        self.data_path = data_path\n",
        "        self.percent_data = percent_data\n",
        "        self.percent_val = percent_val\n",
        "        \n",
        "        if self.dataset == 'hymenoptera':\n",
        "\n",
        "            self.transform = tv.transforms.Compose([\n",
        "                tv.transforms.RandomResizedCrop(224),\n",
        "                tv.transforms.RandomHorizontalFlip(),\n",
        "                tv.transforms.ToTensor(),\n",
        "                tv.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "            \n",
        "        elif self.dataset == 'cifar10' or self.dataset == 'cifar100':\n",
        "\n",
        "            self.transform = tv.transforms.Compose([\n",
        "                tv.transforms.RandomResizedCrop(224),\n",
        "                tv.transforms.RandomHorizontalFlip(),\n",
        "                tv.transforms.ToTensor(),\n",
        "                tv.transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))])\n",
        "        \n",
        "        return\n",
        "    \n",
        "    \n",
        "    def ImportDataset(self, batch_size=5):\n",
        "        \n",
        "        self.batch_size = batch_size\n",
        "        \n",
        "        if self.dataset == 'hymenoptera':\n",
        "        \n",
        "            self.trainset = tv.datasets.ImageFolder(root=self.data_path,\n",
        "                             transform=self.transform)\n",
        "        \n",
        "        # todo\n",
        "        \n",
        "        elif self.dataset == 'cifar10':\n",
        "\n",
        "            self.trainset = tv.datasets.CIFAR10(root=self.data_path, train=True,\n",
        "                                        download=True, transform=self.transform)\n",
        "\n",
        "            self.testset = tv.datasets.CIFAR10(root=self.data_path, train=False,\n",
        "                                       download=True, transform=self.transform)\n",
        "        \n",
        "        elif self.dataset == 'cifar100':\n",
        "\n",
        "            self.trainset = tv.datasets.CIFAR100(root=self.data_path, train=True,\n",
        "                                        download=True, transform=self.transform)\n",
        "\n",
        "            self.testset = tv.datasets.CIFAR100(root=self.data_path, train=False,\n",
        "                                       download=True, transform=self.transform)\n",
        "             \n",
        "        self.SplitData();\n",
        "        self.GenerateLoaders();\n",
        "                \n",
        "        return\n",
        "    \n",
        "    \n",
        "    def SplitData(self):\n",
        "        \n",
        "        len_full = self.trainset.__len__()\n",
        "        len_train = int(np.round(len_full*self.percent_data/100.0))\n",
        "        \n",
        "        _, self.trainset = torch.utils.data.random_split(self.trainset, (len_full-len_train, len_train))\n",
        "        \n",
        "        len_val = int(np.round(len_train*self.percent_val/100.0))\n",
        "        len_train = len_train - len_val\n",
        "        \n",
        "        self.valset, self.trainset = torch.utils.data.random_split(self.trainset, (len_val, len_train))\n",
        "         \n",
        "        len_full_test = self.testset.__len__()\n",
        "        len_test = int(np.round(len_full_test*self.percent_data/100.0))\n",
        "        \n",
        "        _, self.testset = torch.utils.data.random_split(self.testset, (len_full_test-len_test, len_test))\n",
        "\n",
        "        print('\\nFull training set size: {}'.format(len_full))\n",
        "        print('Full test set size: {}'.format(len_full_test))\n",
        "        print('\\nActive training set size: {}'.format(len_train))\n",
        "        print('Active validation set size: {}'.format(len_val))\n",
        "        print('Active test set size: {}\\n'.format(len_test))\n",
        "        \n",
        "        return\n",
        "    \n",
        "    \n",
        "    def GenerateLoaders(self):\n",
        "        \n",
        "        self.train_loader = torch.utils.data.DataLoader(self.trainset, batch_size=self.batch_size,\n",
        "                                          shuffle=True, num_workers=0)\n",
        "        self.val_loader = torch.utils.data.DataLoader(self.valset, batch_size=self.batch_size,\n",
        "                                          shuffle=True, num_workers=0)\n",
        "        self.test_loader = torch.utils.data.DataLoader(self.testset, batch_size=self.batch_size,\n",
        "                                          shuffle=True, num_workers=0)          \n",
        "            \n",
        "        return\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JUJWD_oDBKHD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Training function"
      ]
    },
    {
      "metadata": {
        "id": "34G6XlaFBMUW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train_model(model, dat, criterion, optimizer, scheduler, prune_settings=0, num_epochs=25):\n",
        "    \n",
        "    since = time.time()\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch+1, num_epochs))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'val']:\n",
        "            \n",
        "            if phase == 'train':\n",
        "                scheduler.step()\n",
        "                dataloader = dat.train_loader\n",
        "                dataset_size = dat.trainset.__len__()\n",
        "                \n",
        "                model.train()  # Set model to training mode\n",
        "                \n",
        "            else:\n",
        "                \n",
        "                model.eval()   # Set model to evaluate mode\n",
        "                dataloader = dat.val_loader\n",
        "                dataset_size = dat.valset.__len__()\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # Iterate over data.\n",
        "            for inputs, labels in dataloader:\n",
        "                \n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "                \n",
        "                if prune_settings != 0:\n",
        "                    TrackConv2DNorms(model, prune_settings, inputs)\n",
        "\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward\n",
        "                # track history if training\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            epoch_loss = running_loss / dataset_size\n",
        "            epoch_acc = running_corrects.double() / dataset_size\n",
        "\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
        "                phase, epoch_loss, epoch_acc))\n",
        "            \n",
        "            # Record losses for later use, plotting etc\n",
        "            if phase == 'train':\n",
        "                prune_settings.epoch_loss.append(epoch_loss)\n",
        "                prune_settings.epoch_acc.append(epoch_acc)\n",
        "            elif phase == 'val':\n",
        "                prune_settings.val_loss.append(epoch_loss)\n",
        "                prune_settings.val_acc.append(epoch_acc)\n",
        "\n",
        "            # deep copy the model\n",
        "            if phase == 'val' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
        "        time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best val Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    \n",
        "    return model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "z7C3UubBBXFo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Pruning functions"
      ]
    },
    {
      "metadata": {
        "id": "MaSebsFceMRD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Pruning settings"
      ]
    },
    {
      "metadata": {
        "id": "jAZVF5O-BZNw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "# Constants that define possible pruning metrics\n",
        "WEIGHT_NORM = 1\n",
        "ACT_NORM = 2\n",
        "\n",
        "# Class that contains various settings pertaining to how filters are pruned\n",
        "class UnitPruningSettings:\n",
        "    \n",
        "    def __init__(self, idx_layer=0, idx_filter=0, N_prune=1, P_prune=10, p=2, pruning_metric=WEIGHT_NORM):\n",
        "        \n",
        "        # EITHER N_prune OR P_prune will be used to decide how many filters to prune.\n",
        "        # If one is non-positive, the other is used.\n",
        "        # If neither is non-positive, priority is given to P_prune.\n",
        "        # If both are non-positive, no pruning will happen.\n",
        "\n",
        "        self.N_prune = N_prune # Number of filters allowed to be pruned in one pass\n",
        "        self.P_prune = P_prune; # Percent of filters of the current layer to prune\n",
        "        \n",
        "        self.idx_filter = idx_filter # Indices of the N_prune filters\n",
        "        self.idx_layer = idx_layer # Current layer under consideration\n",
        "        self.p = p # p-norm to use when computing which filters to remove\n",
        "        self.pruning_metric = pruning_metric\n",
        "        \n",
        "        self.norms_botk = []\n",
        "        self.idx_norms_botk = []\n",
        "        \n",
        "        # Various statistics will be stored and computed to keep track of how the network changes\n",
        "        \n",
        "        # Number of filters per layer in the original network\n",
        "        self.filters_per_layer_orig = []\n",
        "        \n",
        "        # Number of filters per layer after pruning - this gets updated every time the network is pruned\n",
        "        self.filters_per_layer_after = []\n",
        "        \n",
        "        # Time taken to prune in sec (running total, updated every time pruning happens)\n",
        "        self.prune_time = 0.0\n",
        "        \n",
        "        # Keep track of running epoch loss and validation loss, and corresponding accuracy\n",
        "        self.epoch_loss = []\n",
        "        self.val_loss = []\n",
        "        self.epoch_acc = []\n",
        "        self.val_acc = []\n",
        "        \n",
        "        return\n",
        "    \n",
        "    # Function to print the current pruning state of the model. Verbose can be 0, 1, or 2.\n",
        "    def PrintPruningStatistics(self, verbose=1):\n",
        "    \n",
        "        if verbose == 0:\n",
        "            return\n",
        "        \n",
        "        print(\"Total number of filters before pruning: {}\".format(sum(self.filters_per_layer_orig)))\n",
        "        print(\"Total number of filters after pruning: {}\".format(sum(self.filters_per_layer_after)))\n",
        "    \n",
        "        return\n",
        "    \n",
        "    # Function to set up and initialize based on a given model\n",
        "    def Setup(self, model):\n",
        "        \n",
        "        # Count the number of conv layers\n",
        "        self.N_layers = 0\n",
        "        \n",
        "        for layer, (name, module) in enumerate(model.features._modules.items()):\n",
        "            self.N_layers += 1\n",
        "                    \n",
        "        # Initialize storage containers\n",
        "        self.norms_botk = [None]*self.N_layers\n",
        "        self.idx_norms_botk = [None]*self.N_layers\n",
        "        \n",
        "    \n",
        "    # Function to reset norm containers\n",
        "    def ResetNormContainers(self):\n",
        "    \n",
        "        self.norms_botk = [None]*self.N_layers\n",
        "        self.idx_norms_botk = [None]*self.N_layers\n",
        "    \n",
        "        return\n",
        "\n",
        "    # Function to reset filter containers\n",
        "    def ResetFilterContainers(self):\n",
        "    \n",
        "        self.filters_per_layer_orig = []\n",
        "        self.filters_per_layer_after = []\n",
        "    \n",
        "        return\n",
        "\n",
        "        \n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Qc41Ng14ezag",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Pruning decisions"
      ]
    },
    {
      "metadata": {
        "id": "2F0n6VUTe2ND",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Function to compute the p-norm of weights in all filters of a given layer.\n",
        "# The list of norms are returned in a list in the same order as that in which filters of that layer are stored.\n",
        "def ComputeConv2DWeightNorms(model, idx_layer, p):\n",
        "    \n",
        "    # Extract the layer of the model currently being considered\n",
        "    _, conv = list(model.features._modules.items())[idx_layer]\n",
        "    weights = conv.weight.data\n",
        "\n",
        "    # Compute norms of each filter\n",
        "    norms = weights.norm(p, dim=2).norm(p, dim=2).norm(p, dim=1)\n",
        "    \n",
        "    return norms\n",
        "\n",
        "\n",
        "# Function to compute the p-norm of activations in all filters per layer.\n",
        "# The list of norms are returned in a list in the same order as that in which filters of that layer are stored.\n",
        "def ComputeConv2DActNorms(activation, prune_settings):\n",
        "    \n",
        "    p = prune_settings.p\n",
        "    \n",
        "    # Compute norms of each activation\n",
        "    norms = torch.norm(activation, p, dim=0).norm(p, dim=1).norm(p, dim=1)\n",
        "        \n",
        "    return norms\n",
        "\n",
        "\n",
        "# Function to track the p-norm of activations of all filters of during training.\n",
        "def TrackConv2DNorms(model, prune_settings, inputs):\n",
        "    \n",
        "    p = prune_settings.p\n",
        "    P_prune = prune_settings.P_prune\n",
        "\n",
        "    x = Variable(inputs)\n",
        "\n",
        "    ii = -1\n",
        "    for layer, (name, module) in enumerate(model.features._modules.items()):\n",
        "        ii += 1\n",
        "        x = module(x)\n",
        "        \n",
        "        if isinstance(module, torch.nn.modules.conv.Conv2d):\n",
        "            \n",
        "            if prune_settings.pruning_metric == WEIGHT_NORM:\n",
        "                norms = ComputeConv2DWeightNorms(model, ii, p)\n",
        "            elif prune_settings.pruning_metric == ACT_NORM:\n",
        "                norms = ComputeConv2DActNorms(x, prune_settings)\n",
        "\n",
        "            # Use the given prune percentage to figure out how many filters to prune\n",
        "            if (P_prune >= 0):\n",
        "                N_prune = int(len(norms.float())*P_prune/100.0)\n",
        "                prune_settings.N_prune = N_prune\n",
        "\n",
        "#             n_botk, ind_botk = torch.topk(norms, N_prune, 0, largest=False, sorted=True, out=None)\n",
        "            norms = norms.cpu().detach().numpy()\n",
        "    \n",
        "            # Store the norms for each filter\n",
        "#             if prune_settings.norms_botk[ii] is None:\n",
        "#                 prune_settings.norms_botk[ii] = norms\n",
        "#             else:\n",
        "#                 prune_settings.norms_botk[ii] += norms\n",
        "                \n",
        "            # Store normalized norms for each filter\n",
        "            if prune_settings.norms_botk[ii] is None:\n",
        "                prune_settings.norms_botk[ii] = norms/max(norms)\n",
        "            else:\n",
        "                prune_settings.norms_botk[ii] += norms/max(norms)\n",
        "                \n",
        "    return"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "U59vXkzfehDX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Pruning workers"
      ]
    },
    {
      "metadata": {
        "id": "RY5GZWxXej1z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# The following functions were adapted from https://github.com/jacobgil/pytorch-pruning/blob/master/prune.py\n",
        "\n",
        "def replace_layers(model, i, idx, layers):\n",
        "\tif i in idx:\n",
        "\t\treturn layers[idx.index(i)]\n",
        "\treturn model[i]\n",
        "\n",
        "\n",
        "# Function to prune a given convolution layer in the model provided.\n",
        "# Input \"idx_layers\" is the global index of the convolution layer to be pruned.\n",
        "# Input \"prune_settings\" is a data structure containing information on how pruning is performed.\n",
        "def PruneConvLayers(model, prune_settings):\n",
        "    \n",
        "    # Strategy: in order to prune a particular layer, the output of the previous layer \n",
        "    # and the inputs to the next layer must also be altered accordingly.\n",
        "\t\n",
        "    # Extract pruning settings for convenience\n",
        "    N_prune = prune_settings.N_prune\n",
        "    idx_filter = prune_settings.idx_filter\n",
        "    idx_layer = prune_settings.idx_layer\n",
        "    \n",
        "    if idx_layer >= len(model.features._modules.items()):\n",
        "        return\n",
        "        \n",
        "    # Extract the layer of the model currently being pruned\n",
        "    _, conv = list(model.features._modules.items())[idx_layer]\n",
        "    \n",
        "\n",
        "    # In case the list of target filters to delete has out-of-range entries, detect and ignore them\n",
        "    del_filters = []\n",
        "    for kk in range(0, len(idx_filter)):\n",
        "        if idx_filter[kk] >= conv.out_channels:\n",
        "            del_filters.extend(kk)\n",
        "    \n",
        "    if (len(del_filters) > 0):\n",
        "        idx_filter = np.delete(idx_filter, del_filters, 0)\n",
        "        N_prune = len(idx_filter)\n",
        "        prune_settings.N_prune = N_prune\n",
        "        print(\"[WARNING] Encountered an out-of-range target filter; it will be ignored.\")\n",
        "    \n",
        "    # Record pruning statistics\n",
        "    prune_settings.filters_per_layer_orig[idx_layer] = conv.out_channels\n",
        "    prune_settings.filters_per_layer_after[idx_layer] = conv.out_channels - N_prune\n",
        "    \n",
        "        \n",
        "    # To keep track of the succeeding convolution layer\n",
        "    next_conv = None\n",
        "    offset = 1\n",
        "    \n",
        "    # Figure out how many layers after this one are NOT conv layers, in order to skip pruning them\n",
        "    while idx_layer + offset < len(model.features._modules.items()):\n",
        "        \n",
        "        res =  list(model.features._modules.items())[idx_layer + offset]\n",
        "        if isinstance(res[1], torch.nn.modules.conv.Conv2d):\n",
        "            next_name, next_conv = res\n",
        "            break\n",
        "        offset = offset + 1\n",
        "    \n",
        "    # Create a new, replacement conv layer to remove a given number of filters.\n",
        "    # The rest of its settings should remain the same as the original conv layer.\n",
        "    new_conv = torch.nn.Conv2d(in_channels = conv.in_channels,\n",
        "                               out_channels = conv.out_channels - N_prune,\n",
        "\t\t\t                   kernel_size = conv.kernel_size,\n",
        "                               stride = conv.stride,\n",
        "                               padding = conv.padding,\n",
        "                               dilation = conv.dilation,\n",
        "                               groups = conv.groups,\n",
        "                               bias = True)\n",
        "    \n",
        "    new_conv.bias = conv.bias\n",
        "    \n",
        "    # Copy over the weights to the new conv layer, except the ones corresponding to the filter to be removed\n",
        "    old_weights = conv.weight.data.cpu().numpy()\n",
        "    new_weights = new_conv.weight.data.cpu().numpy()\n",
        "    \n",
        "    # Copy over the set of filters, excluding the ones to be removed\n",
        "    new_weights_temp = np.copy(old_weights)\n",
        "    new_weights_temp = np.delete(new_weights_temp, idx_filter, 0)\n",
        "    new_weights[:, :, :, :] = new_weights_temp[:, :, :, :]\n",
        "\n",
        "    # Update weight data of the new conv layer\n",
        "    new_conv.weight.data = torch.from_numpy(new_weights).cuda()\n",
        "    \n",
        "    # Now do the same thing for biases\n",
        "    old_biases = conv.bias.data.cpu().numpy()\n",
        "    new_biases = np.zeros(shape=(old_biases.shape[0] - N_prune), dtype=np.float32)\n",
        "    \n",
        "    new_biases_temp = np.copy(old_biases)\n",
        "    new_biases_temp = np.delete(new_biases_temp, idx_filter, 0)\n",
        "    new_biases[:] = new_biases_temp[:]\n",
        "        \n",
        "    new_conv.bias.data = torch.from_numpy(new_biases).cuda()\n",
        "    \n",
        "    # If there is a succeeding conv layer, adjust its input units and weights accordingly\n",
        "    if next_conv != None:\n",
        "        \n",
        "        next_new_conv = torch.nn.Conv2d(in_channels = next_conv.in_channels - N_prune,\n",
        "                                        out_channels =  next_conv.out_channels,\n",
        "                                        kernel_size = next_conv.kernel_size,\n",
        "                                        stride = next_conv.stride,\n",
        "                                        padding = next_conv.padding,\n",
        "                                        dilation = next_conv.dilation,\n",
        "                                        groups = next_conv.groups,\n",
        "                                        bias = True)\n",
        "        \n",
        "        next_new_conv.bias = next_conv.bias\n",
        "\n",
        "        old_weights = next_conv.weight.data.cpu().numpy()\n",
        "        new_weights = next_new_conv.weight.data.cpu().numpy()\n",
        "        \n",
        "        # Copy over the set of filters, excluding the ones to be removed\n",
        "        new_weights_temp = np.copy(old_weights)\n",
        "        new_weights_temp = np.delete(new_weights_temp, idx_filter, 1)\n",
        "        new_weights[:, :, :, :] = new_weights_temp[:, :, :, :]\n",
        "\n",
        "        next_new_conv.weight.data = torch.from_numpy(new_weights).cuda()\n",
        "\n",
        "        # Now do the same thing for biases\n",
        "        next_new_conv.bias.data = next_conv.bias.data\n",
        "\n",
        "        # Update the actual model by replacing the existing filters with the new ones\n",
        "        features = torch.nn.Sequential(\n",
        "                *(replace_layers(model.features, i, [idx_layer, idx_layer + offset], \\\n",
        "                    [new_conv, next_new_conv]) for i, _ in enumerate(model.features)))\n",
        "        del model.features\n",
        "        del conv\n",
        "\n",
        "        model.features = features\n",
        "    \n",
        "    else:\n",
        "\n",
        "        # This is the last conv layer. This affects the first linear layer of the classifier.\n",
        "        model.features = torch.nn.Sequential(*(replace_layers(model.features, i, [idx_layer], [new_conv]) for i, _ in enumerate(model.features)))\n",
        "        idx_layer = 0\n",
        "        old_linear_layer = None\n",
        "\n",
        "        for _, module in model.classifier._modules.items():\n",
        "            if isinstance(module, torch.nn.Linear):\n",
        "                old_linear_layer = module\n",
        "                break\n",
        "            idx_layer = idx_layer + 1\n",
        "\n",
        "        if old_linear_layer == None:\n",
        "            raise BaseException(\"No linear layer found in classifier.\")\n",
        "            \n",
        "        params_per_input_channel = int(old_linear_layer.in_features/conv.out_channels)\n",
        "\n",
        "        new_linear_layer = torch.nn.Linear(old_linear_layer.in_features - N_prune*params_per_input_channel, \n",
        "                                           old_linear_layer.out_features)\n",
        "\n",
        "        old_weights = old_linear_layer.weight.data.cpu().numpy()\n",
        "        new_weights = new_linear_layer.weight.data.cpu().numpy()\t \t\n",
        "\n",
        "        # Copy over the set of filters, excluding the ones to be removed\n",
        "        new_weights_temp = np.copy(old_weights)\n",
        "        idx_expanded = np.zeros(shape=(N_prune*params_per_input_channel))\n",
        "        \n",
        "        for kk in range(0, len(idx_filter)):\n",
        "            idx_expanded[kk*params_per_input_channel:kk*params_per_input_channel+params_per_input_channel] = np.arange(idx_filter[kk]*params_per_input_channel, idx_filter[kk]*params_per_input_channel + params_per_input_channel)\n",
        "\n",
        "        new_weights_temp = np.delete(new_weights_temp, idx_expanded.astype(int), 1)\n",
        "        new_weights[:, :] = new_weights_temp[:, :]\n",
        "        \n",
        "        new_linear_layer.bias.data = old_linear_layer.bias.data\n",
        "        new_linear_layer.weight.data = torch.from_numpy(new_weights).cuda()\n",
        "\n",
        "        classifier = torch.nn.Sequential(*(replace_layers(model.classifier, i, [idx_layer], [new_linear_layer]) for i, _ in enumerate(model.classifier)))\n",
        "\n",
        "        del model.classifier\n",
        "        del next_conv\n",
        "        del conv\n",
        "        model.classifier = classifier\n",
        "        \n",
        "    return model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "D7h5EFGhe-PJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Pruning driver"
      ]
    },
    {
      "metadata": {
        "id": "Xp8V5o_UfADH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Function to iterate through all conv2D layers of the network and determine \n",
        "# filters to be pruned, and then carry out the pruning.\n",
        "def PruneAllConv2DLayers(model, prune_settings):\n",
        "    \n",
        "    # Extract pruning settings for convenience\n",
        "    # Note that \"N_prune\" *consecutive* filters will get pruned\n",
        "    N_prune = prune_settings.N_prune\n",
        "    P_prune = prune_settings.P_prune\n",
        "    p = prune_settings.p\n",
        "    pruning_metric = prune_settings.pruning_metric\n",
        "    \n",
        "    # Count number of prunable layers for preallocation\n",
        "    N_layers = len(model.features._modules.items())       \n",
        "    prune_settings.filters_per_layer_orig = np.zeros(shape=(1, N_layers)).ravel()\n",
        "    prune_settings.filters_per_layer_after = np.zeros(shape=(1, N_layers)).ravel()\n",
        "\n",
        "    \n",
        "    # Find the N_prune filters to remove\n",
        "    ii = 0\n",
        "    while ii < len(model.features._modules.items()):\n",
        "        \n",
        "        res = list(model.features._modules.items())[ii]\n",
        "        \n",
        "        if isinstance(res[1], torch.nn.modules.conv.Conv2d):\n",
        "            \n",
        "            _, conv = list(model.features._modules.items())[ii]\n",
        "            \n",
        "            # Record pruning statistics\n",
        "            prune_settings.filters_per_layer_orig[ii] = conv.out_channels\n",
        "            prune_settings.filters_per_layer_after[ii] = conv.out_channels\n",
        "            \n",
        "            # Compute values and indices of the N_prune smallest norms\n",
        "#             if pruning_metric == WEIGHT_NORM:\n",
        "#                 norms = ComputeConv2DWeightNorms(model, ii, p)\n",
        "#             elif pruning_metric == ACT_NORM:\n",
        "# #                 norms = ComputeConv2DWeightNorms(model, ii, p)\n",
        "#                 norms = ComputeConv2DActNorms(res[1], prune_settings)\n",
        "                \n",
        "        \n",
        "            if (P_prune >= 0):\n",
        "                N_prune = int(conv.out_channels*P_prune/100.0)\n",
        "                prune_settings.N_prune = N_prune\n",
        "            \n",
        "            if prune_settings.norms_botk[ii] is not None:\n",
        "                \n",
        "#                 n_botk, ind_botk = torch.topk(torch.from_numpy(prune_settings.norms_botk[ii]), N_prune, 0, largest=False, sorted=True, out=None)\n",
        "            \n",
        "                norms = np.asarray(prune_settings.norms_botk[ii]).ravel()\n",
        "                ind_botk = np.argpartition(norms, N_prune)    \n",
        "                n_botk = norms[ind_botk[:N_prune]]\n",
        "                ind_botk = ind_botk[:N_prune]\n",
        "        \n",
        "                prune_settings.idx_layer = ii\n",
        "                prune_settings.idx_filter = ind_botk\n",
        "\n",
        "                model = PruneConvLayers(model, prune_settings)\n",
        "                \n",
        "        ii = ii + 1\n",
        "            \n",
        "    return model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cCEASFCwB3uP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Test Pruning"
      ]
    },
    {
      "metadata": {
        "id": "LmuhhazDB6d7",
        "colab_type": "code",
        "outputId": "cff3f6aa-5f5c-4935-9ce6-d55736a3cabc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "# Test pruning\n",
        "\n",
        "model = models.vgg16(pretrained=True)\n",
        "model.train()\n",
        "\n",
        "# Pruning setup\n",
        "prune_settings = UnitPruningSettings(idx_layer=28, idx_filter=(10, 12, 15, 16, 21), \n",
        "                                     N_prune=5, p=2, pruning_metric=WEIGHT_NORM)\n",
        "# prune_settings = UnitPruningSettings(idx_layer=28, idx_filter=(10), \n",
        "#                                      N_prune=1, p=2, pruning_metric=WEIGHT_NORM)\n",
        "\n",
        "N_layers = len(model.features._modules.items())       \n",
        "prune_settings.filters_per_layer_orig = np.zeros(shape=(1, N_layers)).ravel()\n",
        "prune_settings.filters_per_layer_after = np.zeros(shape=(1, N_layers)).ravel()\n",
        "\n",
        "t0 = time.time()\n",
        "model = PruneConvLayers(model, prune_settings)\n",
        "print (\"Pruning took {} s\".format(time.time() - t0))\n"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Pruning took 4.067852735519409 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0tfmvixSCzAH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Model Setup Routines"
      ]
    },
    {
      "metadata": {
        "id": "fF2ZhlgCC31h",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Baseline Model Setup"
      ]
    },
    {
      "metadata": {
        "id": "GeD0hZfpDHbr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model_baseline = models.vgg16(pretrained=False)\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model_baseline = model_baseline.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Observe that all parameters are being optimized\n",
        "optimizer = optim.SGD(model_baseline.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# Decay LR by a factor of 0.1 every 7 epochs\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lc0YTkyADA63",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Pruned Model Setup"
      ]
    },
    {
      "metadata": {
        "id": "cr4wgE6eDKND",
        "colab_type": "code",
        "outputId": "0f2c5d59-5f0f-4a76-918f-858c3ab87e1d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 358
        }
      },
      "cell_type": "code",
      "source": [
        "# Test pruning all layers\n",
        "\n",
        "model_pruned = models.vgg16(pretrained=True)\n",
        "model_pruned.train()\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model_pruned = model_pruned.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Observe that all parameters are being optimized\n",
        "optimizer = optim.SGD(model_pruned.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# Decay LR by a factor of 0.1 every 7 epochs\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
        "\n",
        "# Pruning setup\n",
        "prune_settings = UnitPruningSettings(28, 10, N_prune = 4, p = 2, pruning_metric = WEIGHT_NORM)\n",
        "\n",
        "t0 = time.time()\n",
        "model_pruned = PruneAllConv2DLayers(model_pruned, prune_settings)\n",
        "print (\"Pruning took {} s\".format(time.time() - t0))\n"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-c16a3b839ee5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mt0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mmodel_pruned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPruneAllConv2DLayers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_pruned\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprune_settings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"Pruning took {} s\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-34-68787035a1e4>\u001b[0m in \u001b[0;36mPruneAllConv2DLayers\u001b[0;34m(model, prune_settings)\u001b[0m\n\u001b[1;32m     40\u001b[0m                 \u001b[0mprune_settings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mN_prune\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mN_prune\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mprune_settings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorms_botk\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mii\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;31m#                 n_botk, ind_botk = torch.topk(torch.from_numpy(prune_settings.norms_botk[ii]), N_prune, 0, largest=False, sorted=True, out=None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "coPfbZmXE3T0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Driver Routines"
      ]
    },
    {
      "metadata": {
        "id": "DS7qbZ0JE6Fs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Iterative Pruning"
      ]
    },
    {
      "metadata": {
        "id": "E1q-h_KTE-kE",
        "colab_type": "code",
        "outputId": "84715710-7811-414e-9378-05bf383e2a47",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2162
        }
      },
      "cell_type": "code",
      "source": [
        "# ====== Dataset setup ======\n",
        "\n",
        "percent_data = 1.0\n",
        "percent_val = 20.0\n",
        "batch_size = 5\n",
        "\n",
        "\n",
        "# ====== Model setup ======\n",
        "\n",
        "model = models.vgg16(pretrained=False)\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "\n",
        "\n",
        "# ====== Pruning setup ======\n",
        "\n",
        "N_prune = 0\n",
        "P_prune = 5\n",
        "p = 2\n",
        "prune_settings = UnitPruningSettings(N_prune=N_prune, \n",
        "                                     P_prune=P_prune, \n",
        "                                     p=p, \n",
        "                                     pruning_metric=ACT_NORM)\n",
        "prune_settings.Setup(model)\n",
        "\n",
        "\n",
        "# ====== Begin training ======\n",
        "\n",
        "N_iter_outer = 2\n",
        "N_iter_inner = 2\n",
        "\n",
        "# Import data\n",
        "dat = DatasetManager(dataset='cifar10', \n",
        "                     percent_data=percent_data, \n",
        "                     percent_val=percent_val)\n",
        "\n",
        "dat.ImportDataset(batch_size=batch_size)\n",
        "\n",
        "for ii in range(0, N_iter_outer):\n",
        "    \n",
        "    print(\"\\n------ Outer iteration {}/{} ------\".format(ii+1, N_iter_outer))\n",
        "#     t0 = time.time()\n",
        "\n",
        "    # ------ Prune current model ------\n",
        "        \n",
        "    model = PruneAllConv2DLayers(model, prune_settings)\n",
        "    new_model = copy.deepcopy(model)\n",
        "    model = new_model\n",
        "    prune_settings.PrintPruningStatistics(1)\n",
        "    prune_settings.ResetNormContainers()\n",
        "\n",
        "    # ------ Train current model ------\n",
        "    \n",
        "    # Import data\n",
        "    dat = DatasetManager(dataset='cifar10', percent_data=percent_data, percent_val=percent_val)\n",
        "    dat.ImportDataset(batch_size=batch_size)\n",
        "    \n",
        "    # Update optimizer\n",
        "    optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "    # Decay LR by a factor of 0.1 every 7 epochs\n",
        "    exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    \n",
        "    model = train_model(model, dat, criterion, optimizer, exp_lr_scheduler, prune_settings, num_epochs=N_iter_inner)\n",
        "        \n",
        "#     print (\"Pruning took {} s\".format(time.time() - t0))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "\n",
            "Full training set size: 50000\n",
            "Full test set size: 10000\n",
            "\n",
            "Active training set size: 400\n",
            "Active validation set size: 100\n",
            "Active test set size: 100\n",
            "\n",
            "\n",
            "------ Outer iteration 1/2 ------\n",
            "Total number of filters before pruning: 4224.0\n",
            "Total number of filters after pruning: 4224.0\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "\n",
            "Full training set size: 50000\n",
            "Full test set size: 10000\n",
            "\n",
            "Active training set size: 400\n",
            "Active validation set size: 100\n",
            "Active test set size: 100\n",
            "\n",
            "Epoch 1/2\n",
            "----------\n",
            "train Loss: 4.2360 Acc: 0.1000\n",
            "val Loss: 2.7906 Acc: 0.1100\n",
            "\n",
            "Epoch 2/2\n",
            "----------\n",
            "train Loss: 2.6391 Acc: 0.1025\n",
            "val Loss: 2.6396 Acc: 0.0700\n",
            "\n",
            "Training complete in 0m 33s\n",
            "Best val Acc: 0.110000\n",
            "\n",
            "------ Outer iteration 2/2 ------\n",
            "Total number of filters before pruning: 4224.0\n",
            "Total number of filters after pruning: 4020.0\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "\n",
            "Full training set size: 50000\n",
            "Full test set size: 10000\n",
            "\n",
            "Active training set size: 400\n",
            "Active validation set size: 100\n",
            "Active test set size: 100\n",
            "\n",
            "Epoch 1/2\n",
            "----------\n",
            "train Loss: 2.6741 Acc: 0.0900\n",
            "val Loss: 2.4831 Acc: 0.0800\n",
            "\n",
            "Epoch 2/2\n",
            "----------\n",
            "train Loss: 2.5480 Acc: 0.0875\n",
            "val Loss: 2.3854 Acc: 0.1400\n",
            "\n",
            "Training complete in 0m 33s\n",
            "Best val Acc: 0.140000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/matplotlib/legend.py:798: UserWarning: Legend does not support 'E' instances.\n",
            "A proxy artist may be used instead.\n",
            "See: http://matplotlib.org/users/legend_guide.html#creating-artists-specifically-for-adding-to-the-legend-aka-proxy-artists\n",
            "  \"aka-proxy-artists\".format(orig_handle)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/legend.py:798: UserWarning: Legend does not support 'p' instances.\n",
            "A proxy artist may be used instead.\n",
            "See: http://matplotlib.org/users/legend_guide.html#creating-artists-specifically-for-adding-to-the-legend-aka-proxy-artists\n",
            "  \"aka-proxy-artists\".format(orig_handle)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/legend.py:798: UserWarning: Legend does not support 'o' instances.\n",
            "A proxy artist may be used instead.\n",
            "See: http://matplotlib.org/users/legend_guide.html#creating-artists-specifically-for-adding-to-the-legend-aka-proxy-artists\n",
            "  \"aka-proxy-artists\".format(orig_handle)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/legend.py:798: UserWarning: Legend does not support 'c' instances.\n",
            "A proxy artist may be used instead.\n",
            "See: http://matplotlib.org/users/legend_guide.html#creating-artists-specifically-for-adding-to-the-legend-aka-proxy-artists\n",
            "  \"aka-proxy-artists\".format(orig_handle)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/legend.py:798: UserWarning: Legend does not support 'h' instances.\n",
            "A proxy artist may be used instead.\n",
            "See: http://matplotlib.org/users/legend_guide.html#creating-artists-specifically-for-adding-to-the-legend-aka-proxy-artists\n",
            "  \"aka-proxy-artists\".format(orig_handle)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/legend.py:798: UserWarning: Legend does not support ' ' instances.\n",
            "A proxy artist may be used instead.\n",
            "See: http://matplotlib.org/users/legend_guide.html#creating-artists-specifically-for-adding-to-the-legend-aka-proxy-artists\n",
            "  \"aka-proxy-artists\".format(orig_handle)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/legend.py:798: UserWarning: Legend does not support 'l' instances.\n",
            "A proxy artist may be used instead.\n",
            "See: http://matplotlib.org/users/legend_guide.html#creating-artists-specifically-for-adding-to-the-legend-aka-proxy-artists\n",
            "  \"aka-proxy-artists\".format(orig_handle)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/legend.py:798: UserWarning: Legend does not support 's' instances.\n",
            "A proxy artist may be used instead.\n",
            "See: http://matplotlib.org/users/legend_guide.html#creating-artists-specifically-for-adding-to-the-legend-aka-proxy-artists\n",
            "  \"aka-proxy-artists\".format(orig_handle)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-50-aee74870a634>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m plt.plot(np.arange(1, N_iter_outer*N_iter_inner+1), \n\u001b[0;32m---> 94\u001b[0;31m          \u001b[0mprune_settings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch_acc\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m          \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'red'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m          \u001b[0mmarker\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mmarkersize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: can't multiply sequence by non-int of type 'float'"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEKCAYAAAAB0GKPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJv8fdiJLIcQ7fM4AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "v7ORnILPDbVu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Plot"
      ]
    },
    {
      "metadata": {
        "id": "Icv-APyJDdB5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 550
        },
        "outputId": "6971b5d4-0f20-4581-8e6d-79fafb26a9b2"
      },
      "cell_type": "code",
      "source": [
        "# ====== Plot ======\n",
        "\n",
        "# ------ Loss ------\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(np.arange(1, N_iter_outer*N_iter_inner+1), \n",
        "         prune_settings.epoch_loss, \n",
        "         color='red', \n",
        "         marker='',  markersize=12, \n",
        "         linestyle='-', linewidth=2,\n",
        "         label='Epoch loss')\n",
        "plt.plot(np.arange(1, N_iter_outer*N_iter_inner+1), \n",
        "         prune_settings.val_loss, \n",
        "         color='blue', \n",
        "         marker='',  markersize=12, \n",
        "         linestyle='-', linewidth=2,\n",
        "         label='Validation loss')\n",
        "plt.xlabel('Iteration')\n",
        "plt.ylabel('Loss')\n",
        "plt.grid()\n",
        "\n",
        "# ------ Accuracy ------\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(np.arange(1, N_iter_outer*N_iter_inner+1), \n",
        "         np.asarray(prune_settings.epoch_acc)*100.0, \n",
        "         color='red', \n",
        "         marker='',  markersize=12, \n",
        "         linestyle='-', linewidth=2,\n",
        "         label='Epoch accuracy')\n",
        "plt.plot(np.arange(1, N_iter_outer*N_iter_inner+1), \n",
        "         np.asarray(prune_settings.val_acc)*100.0, \n",
        "         color='blue', \n",
        "         marker='',  markersize=12, \n",
        "         linestyle='-', linewidth=2,\n",
        "         label = 'Validation accuracy')\n",
        "plt.xlabel('Iteration')\n",
        "plt.ylabel('Accuracy (%)')\n",
        "plt.grid()\n"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEKCAYAAAAB0GKPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nhoiIZOX/Az2cmm4F97cYAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEKCAYAAAAfGVI8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nXIbzROCccxnu/wO97prGJj42QQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "UQlUKtFYD5pc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Training Routines"
      ]
    },
    {
      "metadata": {
        "id": "VASgSU9KD-81",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Train Baseline Model"
      ]
    },
    {
      "metadata": {
        "id": "yNR6vmDhEBT6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Import data\n",
        "dat = DatasetManager('cifar10', 1.0, 20.0)\n",
        "dat.ImportDataset(5)\n",
        "\n",
        "model_baseline.train()\n",
        "\n",
        "model_baseline = train_model(model_baseline, dat, criterion, optimizer, exp_lr_scheduler, num_epochs=25)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_wR099MzELCI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Train Pruned Model"
      ]
    },
    {
      "metadata": {
        "id": "0eNeKM87EN6T",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Import data\n",
        "dat = DatasetManager('cifar10', 1.0, 20.0)\n",
        "dat.ImportDataset(5)\n",
        "\n",
        "model.train()\n",
        "\n",
        "model = train_model(model, dat, criterion, optimizer, exp_lr_scheduler, num_epochs=25)\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}